"""
Enhanced Storyline Generator with OpenRouter Structured Outputs and Tool Calling Support
"""

import json
import re
import os
import time
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple


class EnhancedStorylineGenerator:
    """å¢å¼ºçš„æ•…äº‹çº¿ç”Ÿæˆå™¨ï¼Œæ”¯æŒOpenRouterçš„structured outputså’Œtool calling"""

    def __init__(self, chatLLM):
        self.chatLLM = chatLLM
        self.max_retries = 2
        self.provider_name = self._detect_provider()
        
        # æˆªæ–­æ£€æµ‹é…ç½®
        self.truncation_detection = {
            "enabled": True,              # æ˜¯å¦å¯ç”¨æˆªæ–­æ£€æµ‹
            "show_context_lines": 5,      # æ˜¾ç¤ºä¸Šä¸‹æ–‡è¡Œæ•°
            "show_detailed_analysis": True, # æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†åˆ†æ
            "min_content_length": 50       # æœ€å°å†…å®¹é•¿åº¦é˜ˆå€¼
        }
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_attempts": 0,
            "successful_generations": 0, 
            "truncation_detected": 0,
            "json_repair_success": 0,
            "progressive_fallback_used": 0,
            "provider_specific_fixes": 0
        }

    def _detect_provider(self):
        """æ£€æµ‹å½“å‰ä½¿ç”¨çš„æä¾›å•†"""
        try:
            from dynamic_config_manager import get_config_manager
            config_manager = get_config_manager()
            return config_manager.get_current_provider().lower()
        except:
            return "unknown"

    def _supports_advanced_features(self):
        """æ£€æŸ¥å½“å‰æä¾›å•†æ˜¯å¦æ”¯æŒé«˜çº§åŠŸèƒ½ï¼ˆstructured outputså’Œtool callingï¼‰"""
        # åªæœ‰OpenRouterå®Œå…¨æ”¯æŒStructured Outputså’ŒTool Calling
        return self.provider_name == "openrouter"
    
    def _supports_tool_calling(self):
        """æ£€æŸ¥å½“å‰æä¾›å•†æ˜¯å¦æ”¯æŒå·¥å…·è°ƒç”¨ï¼ˆä½†å¯èƒ½æœ‰æ ¼å¼é™åˆ¶ï¼‰"""
        # åªæœ‰OpenRouteræ”¯æŒå·¥å…·è°ƒç”¨ï¼ŒLM Studioå·²ç¦ç”¨tool calling
        return self.provider_name in ["openrouter"]

    def _save_error_data(self, error_type: str, original_messages: List[Dict[str, str]],
                        response_content: str, error_details: str, attempt_number: int = 1):
        """ä¿å­˜é”™è¯¯æ•°æ®åˆ°å…ƒæ•°æ®æ–‡ä»¶ä»¥ä¾›åˆ†æ"""
        try:
            # åˆ›å»ºé”™è¯¯æ•°æ®ç›®å½•
            error_dir = "metadata/storyline_errors"
            os.makedirs(error_dir, exist_ok=True)

            # ç”Ÿæˆé”™è¯¯æ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            error_filename = f"storyline_error_{timestamp}_{error_type}_attempt{attempt_number}.json"
            error_filepath = os.path.join(error_dir, error_filename)

            # æ„å»ºé”™è¯¯æ•°æ®
            error_data = {
                "timestamp": datetime.now().isoformat(),
                "provider": self.provider_name,
                "error_type": error_type,
                "attempt_number": attempt_number,
                "error_details": error_details,
                "original_messages": original_messages,
                "response_content": response_content,
                "response_length": len(response_content) if response_content else 0,
                "analysis": {
                    "has_json_markers": "```json" in response_content.lower() if response_content else False,
                    "has_braces": "{" in response_content and "}" in response_content if response_content else False,
                    "has_chapters_key": "chapters" in response_content.lower() if response_content else False,
                    "response_preview": response_content[:200] if response_content else "",
                    "response_suffix": response_content[-200:] if response_content and len(response_content) > 200 else ""
                },
                "repair_attempts": {
                    "json_candidates_found": 0,
                    "repair_methods_tried": [],
                    "reconstruction_attempted": False
                }
            }

            # å°è¯•åˆ†æJSONå€™é€‰
            if response_content:
                candidates = self._extract_json_candidates(response_content)
                error_data["repair_attempts"]["json_candidates_found"] = len(candidates)
                if candidates:
                    error_data["repair_attempts"]["best_candidate"] = candidates[0][:500] if candidates[0] else ""

            # ä¿å­˜é”™è¯¯æ•°æ®
            with open(error_filepath, 'w', encoding='utf-8') as f:
                json.dump(error_data, f, ensure_ascii=False, indent=2)

            print(f"ğŸ’¾ é”™è¯¯æ•°æ®å·²ä¿å­˜: {error_filepath}")

            # æ›´æ–°é”™è¯¯ç»Ÿè®¡
            self._update_error_statistics(error_type)

        except Exception as e:
            print(f"âš ï¸ ä¿å­˜é”™è¯¯æ•°æ®å¤±è´¥: {e}")

    def _update_error_statistics(self, error_type: str):
        """æ›´æ–°é”™è¯¯ç»Ÿè®¡ä¿¡æ¯"""
        try:
            stats_file = "metadata/storyline_error_stats.json"

            # è¯»å–ç°æœ‰ç»Ÿè®¡
            if os.path.exists(stats_file):
                with open(stats_file, 'r', encoding='utf-8') as f:
                    stats = json.load(f)
            else:
                stats = {
                    "total_errors": 0,
                    "error_types": {},
                    "provider_stats": {},
                    "last_updated": None
                }

            # æ›´æ–°ç»Ÿè®¡
            stats["total_errors"] += 1
            stats["error_types"][error_type] = stats["error_types"].get(error_type, 0) + 1
            stats["provider_stats"][self.provider_name] = stats["provider_stats"].get(self.provider_name, 0) + 1
            stats["last_updated"] = datetime.now().isoformat()

            # ä¿å­˜ç»Ÿè®¡
            os.makedirs("metadata", exist_ok=True)
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump(stats, f, ensure_ascii=False, indent=2)

        except Exception as e:
            print(f"âš ï¸ æ›´æ–°é”™è¯¯ç»Ÿè®¡å¤±è´¥: {e}")

    def _log_successful_generation(self, method: str, attempt_number: int, result_data: Dict[str, Any]):
        """è®°å½•æˆåŠŸçš„ç”Ÿæˆæ¡ˆä¾‹ä»¥ä¾›åˆ†æ"""
        try:
            success_dir = "metadata/storyline_success"
            os.makedirs(success_dir, exist_ok=True)

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            success_filename = f"storyline_success_{timestamp}_{method}_attempt{attempt_number}.json"
            success_filepath = os.path.join(success_dir, success_filename)

            success_data = {
                "timestamp": datetime.now().isoformat(),
                "provider": self.provider_name,
                "method": method,
                "attempt_number": attempt_number,
                "chapters_generated": len(result_data.get("chapters", [])),
                "result_structure": {
                    "has_batch_info": "batch_info" in result_data,
                    "chapter_fields": list(result_data.get("chapters", [{}])[0].keys()) if result_data.get("chapters") else []
                }
            }

            with open(success_filepath, 'w', encoding='utf-8') as f:
                json.dump(success_data, f, ensure_ascii=False, indent=2)

        except Exception as e:
            print(f"âš ï¸ è®°å½•æˆåŠŸæ¡ˆä¾‹å¤±è´¥: {e}")
        
    def get_storyline_schema(self, expected_count: int = 10) -> Dict[str, Any]:
        """è·å–æ•…äº‹çº¿çš„JSON Schemaï¼ŒåŠ¨æ€è®¾ç½®ç« èŠ‚æ•°é‡çº¦æŸ"""
        return {
            "type": "json_schema",
            "json_schema": {
                "name": "storyline_response",
                "schema": {
                    "type": "object",
                    "properties": {
                        "chapters": {
                            "type": "array",
                            "minItems": expected_count,
                            "maxItems": expected_count,
                            "items": {
                                "type": "object",
                                "properties": {
                                    "chapter_number": {"type": "integer"},
                                    "title": {"type": "string"},
                                    "plot_summary": {"type": "string"},
                                    "key_events": {
                                        "type": "array",
                                        "items": {"type": "string"}
                                    },
                                    "character_development": {"type": "string"},
                                    "chapter_mood": {"type": "string"}
                                },
                                "required": ["chapter_number", "title", "plot_summary"]
                            }
                        },
                        "batch_info": {
                            "type": "object",
                            "properties": {
                                "start_chapter": {"type": "integer"},
                                "end_chapter": {"type": "integer"},
                                "total_chapters": {"type": "integer"}
                            },
                            "required": ["start_chapter", "end_chapter"]
                        }
                    },
                    "required": ["chapters", "batch_info"]
                },
                "strict": True
                        }
        }
    
    def _extract_chapter_count_from_messages(self, messages: List[Dict[str, str]]) -> int:
        """ä»æç¤ºè¯ä¸­æå–æœŸæœ›çš„ç« èŠ‚æ•°é‡"""
        if not messages:
            return 10  # é»˜è®¤å€¼
    
    def get_statistics_report(self) -> str:
        """è·å–è¯¦ç»†çš„ç»Ÿè®¡æŠ¥å‘Š"""
        stats = self.stats
        total = max(stats["total_attempts"], 1)  # é¿å…é™¤é›¶é”™è¯¯
        
        success_rate = (stats["successful_generations"] / total) * 100
        truncation_rate = (stats["truncation_detected"] / total) * 100
        repair_rate = (stats["json_repair_success"] / max(stats["truncation_detected"], 1)) * 100
        
        report = f"""
ğŸ“Š æ•…äº‹çº¿ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
{'='*50}
ğŸ“ˆ æ€»ä½“ç»Ÿè®¡:
   â€¢ æ€»å°è¯•æ¬¡æ•°: {stats['total_attempts']}
   â€¢ æˆåŠŸç”Ÿæˆ: {stats['successful_generations']}
   â€¢ æˆåŠŸç‡: {success_rate:.1f}%

ğŸš¨ æˆªæ–­æ£€æµ‹:
   â€¢ æ£€æµ‹åˆ°æˆªæ–­: {stats['truncation_detected']}
   â€¢ æˆªæ–­ç‡: {truncation_rate:.1f}%
   
ğŸ”§ ä¿®å¤ç»Ÿè®¡:
   â€¢ JSONä¿®å¤æˆåŠŸ: {stats['json_repair_success']}
   â€¢ ä¿®å¤æˆåŠŸç‡: {repair_rate:.1f}%
   â€¢ æ¸è¿›å¼é™çº§ä½¿ç”¨: {stats['progressive_fallback_used']}
   â€¢ æä¾›å•†ç‰¹å®šä¿®å¤: {stats['provider_specific_fixes']}

ğŸ¯ å½“å‰æä¾›å•†: {self.provider_name.upper()}
âš™ï¸ æˆªæ–­æ£€æµ‹: {'å¯ç”¨' if self.truncation_detection['enabled'] else 'ç¦ç”¨'}
{'='*50}
"""
        return report
    
    def reset_statistics(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.stats = {
            "total_attempts": 0,
            "successful_generations": 0, 
            "truncation_detected": 0,
            "json_repair_success": 0,
            "progressive_fallback_used": 0,
            "provider_specific_fixes": 0
        }
        print("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®")
    
    def configure_truncation_detection(self, **kwargs):
        """é…ç½®æˆªæ–­æ£€æµ‹å‚æ•°"""
        for key, value in kwargs.items():
            if key in self.truncation_detection:
                old_value = self.truncation_detection[key]
                self.truncation_detection[key] = value
                print(f"ğŸ”§ æˆªæ–­æ£€æµ‹é…ç½®å·²æ›´æ–°: {key} = {old_value} â†’ {value}")
            else:
                print(f"âš ï¸ æœªçŸ¥é…ç½®é¡¹: {key}")
    
    def _record_success(self, method_type: str):
        """è®°å½•æˆåŠŸç”Ÿæˆ"""
        self.stats["successful_generations"] += 1
        
        if method_type in ["enhanced_json_repair", "traditional_repair"]:
            self.stats["json_repair_success"] += 1
        
        if method_type.startswith("progressive_"):
            self.stats["progressive_fallback_used"] += 1
            
        if self.provider_name == "lmstudio" and "truncation" in method_type:
            self.stats["provider_specific_fixes"] += 1
    
    def print_statistics(self):
        """æ‰“å°ç»Ÿè®¡æŠ¥å‘Šåˆ°æ§åˆ¶å°"""
        print(self.get_statistics_report())
    
    def _debug_chapter_count(self, data: Dict[str, Any], expected_count: int, method_name: str) -> None:
        """è°ƒè¯•ç« èŠ‚æ•°é‡ä¿¡æ¯"""
        actual_chapters = data.get("chapters", [])
        actual_count = len(actual_chapters)
        
        print(f"ğŸ“Š {method_name}ç”Ÿæˆç« èŠ‚æ•°é‡: æœŸæœ›{expected_count}ç« ï¼Œå®é™…{actual_count}ç« ")
        
        # å¦‚æœç« èŠ‚æ•°é‡ä¸ç¬¦åˆé¢„æœŸï¼Œæ˜¾ç¤ºè¯¦ç»†è°ƒè¯•ä¿¡æ¯
        if actual_count != expected_count:
            print(f"âš ï¸ ç« èŠ‚æ•°é‡ä¸ç¬¦åˆé¢„æœŸï¼")
            print("ğŸ” è°ƒè¯•ä¿¡æ¯ - è¿”å›çš„åŸå§‹æ•°æ®:")
            print("="*80)
            import json
            print(json.dumps(data, ensure_ascii=False, indent=2))
            print("="*80)
            
            if actual_count == 0:
                print("âŒ æ²¡æœ‰ç”Ÿæˆä»»ä½•ç« èŠ‚")
            elif actual_count < expected_count:
                missing_count = expected_count - actual_count
                print(f"âŒ ç¼ºå¤±{missing_count}ç« ")
                
                # æ˜¾ç¤ºå®é™…ç”Ÿæˆçš„ç« èŠ‚å·
                if actual_chapters:
                    chapter_nums = [ch.get('chapter_number', 'unknown') for ch in actual_chapters]
                    print(f"ğŸ“ å®é™…ç”Ÿæˆçš„ç« èŠ‚å·: {chapter_nums}")
                    
                    # åˆ†æç« èŠ‚å·æ˜¯å¦è¿ç»­
                    if len(chapter_nums) > 1:
                        sorted_nums = sorted([n for n in chapter_nums if isinstance(n, int)])
                        if sorted_nums:
                            gaps = []
                            for i in range(1, len(sorted_nums)):
                                if sorted_nums[i] - sorted_nums[i-1] > 1:
                                    gaps.append((sorted_nums[i-1] + 1, sorted_nums[i] - 1))
                            if gaps:
                                print(f"ğŸ“ å‘ç°ç« èŠ‚å·é—´éš™: {gaps}")
            elif actual_count > expected_count:
                extra_count = actual_count - expected_count
                print(f"âŒ å¤šç”Ÿæˆäº†{extra_count}ç« ")
                
                # æ˜¾ç¤ºæ‰€æœ‰ç« èŠ‚å·
                chapter_nums = [ch.get('chapter_number', 'unknown') for ch in actual_chapters]
                print(f"ğŸ“ ç”Ÿæˆçš„ç« èŠ‚å·: {chapter_nums}")
                
                # æ˜¾ç¤ºé‡å¤çš„ç« èŠ‚å·
                from collections import Counter
                counter = Counter(chapter_nums)
                duplicates = {k: v for k, v in counter.items() if v > 1}
                if duplicates:
                    print(f"ğŸ“ å‘ç°é‡å¤ç« èŠ‚å·: {duplicates}")

    def get_storyline_tools(self, expected_count: int = 10) -> List[Dict[str, Any]]:
        """è·å–æ•…äº‹çº¿ç”Ÿæˆçš„å·¥å…·å®šä¹‰ï¼ŒåŠ¨æ€è®¾ç½®ç« èŠ‚æ•°é‡çº¦æŸ"""
        return [
            {
                "type": "function",
                "function": {
                    "name": "generate_storyline_batch",
                    "description": f"ç”Ÿæˆä¸€æ‰¹æ•…äº‹çº¿ç« èŠ‚ï¼ˆå¿…é¡»ç”Ÿæˆ{expected_count}ç« ï¼‰",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "chapters": {
                                "type": "array",
                                "description": f"ç« èŠ‚åˆ—è¡¨ï¼ˆå¿…é¡»åŒ…å«{expected_count}ç« ï¼‰",
                                "minItems": expected_count,
                                "maxItems": expected_count,
                                "items": {
                                    "type": "object",
                                    "properties": {
                                        "chapter_number": {
                                            "type": "integer",
                                            "description": "ç« èŠ‚å·"
                                        },
                                        "title": {
                                            "type": "string",
                                            "description": "ç« èŠ‚æ ‡é¢˜"
                                        },
                                        "plot_summary": {
                                            "type": "string",
                                            "description": "æƒ…èŠ‚æ¢—æ¦‚"
                                        },
                                        "key_events": {
                                            "type": "array",
                                            "description": "å…³é”®äº‹ä»¶åˆ—è¡¨",
                                            "items": {"type": "string"}
                                        },
                                        "character_development": {
                                            "type": "string",
                                            "description": "äººç‰©å‘å±•"
                                        },
                                        "chapter_mood": {
                                            "type": "string",
                                            "description": "ç« èŠ‚æƒ…ç»ª"
                                        }
                                    },
                                    "required": ["chapter_number", "title", "plot_summary"]
                                }
                            },
                            "batch_info": {
                                "type": "object",
                                "description": "æ‰¹æ¬¡ä¿¡æ¯",
                                "properties": {
                                    "start_chapter": {"type": "integer"},
                                    "end_chapter": {"type": "integer"},
                                    "total_chapters": {"type": "integer"}
                                },
                                "required": ["start_chapter", "end_chapter"]
                            }
                        },
                        "required": ["chapters", "batch_info"]
                    }
                }
            }
        ]
    
    def fix_json_format(self, text: str) -> Optional[Dict[str, Any]]:
        """å¢å¼ºçš„JSONä¿®å¤åŠŸèƒ½ï¼Œä¸“é—¨é’ˆå¯¹Lambdaç­‰ä¸æ”¯æŒç»“æ„åŒ–è¾“å‡ºçš„æä¾›å•†"""
        if not text:
            return None

        print(f"ğŸ”§ å¼€å§‹JSONä¿®å¤ï¼ŒåŸå§‹å†…å®¹é•¿åº¦: {len(text)}å­—ç¬¦")
        
        # ç‰¹æ®Šå¤„ç†ï¼šLM Studioæˆªæ–­é—®é¢˜
        if self.provider_name == "lmstudio" and len(text) < 500:
            print("ğŸ”§ æ£€æµ‹åˆ°LM Studioå¯èƒ½çš„æˆªæ–­é—®é¢˜ï¼Œå°è¯•ä¿®å¤...")
            fixed_truncated = self._fix_lmstudio_truncation(text)
            if fixed_truncated:
                print("âœ… LM Studioæˆªæ–­ä¿®å¤æˆåŠŸ")
                self._record_success("lmstudio_truncation_fix")
                return fixed_truncated

        # ç¬¬ä¸€æ­¥ï¼šæå–å¯èƒ½çš„JSONå†…å®¹
        json_candidates = self._extract_json_candidates(text)

        # ç¬¬äºŒæ­¥ï¼šå¯¹æ¯ä¸ªå€™é€‰è¿›è¡Œä¿®å¤å°è¯•
        for i, candidate in enumerate(json_candidates):
            print(f"ğŸ”§ å°è¯•ä¿®å¤å€™é€‰JSON {i+1}/{len(json_candidates)}")
            fixed_json = self._repair_json_content(candidate)
            if fixed_json:
                print(f"âœ… JSONä¿®å¤æˆåŠŸï¼Œä½¿ç”¨å€™é€‰ {i+1}")
                return fixed_json

        # ç¬¬ä¸‰æ­¥ï¼šå¦‚æœæ‰€æœ‰å€™é€‰éƒ½å¤±è´¥ï¼Œå°è¯•æ™ºèƒ½é‡æ„
        print("ğŸ”§ å°è¯•æ™ºèƒ½é‡æ„JSON...")
        reconstructed = self._reconstruct_json_from_text(text)
        if reconstructed:
            print("âœ… JSONæ™ºèƒ½é‡æ„æˆåŠŸ")
            return reconstructed

        print("âŒ æ‰€æœ‰JSONä¿®å¤æ–¹æ³•éƒ½å¤±è´¥")
        return None
    
    def _fix_lmstudio_truncation(self, text: str) -> Optional[Dict[str, Any]]:
        """ä¸“é—¨ä¿®å¤LM Studioçš„æˆªæ–­é—®é¢˜"""
        try:
            print("ğŸ”§ å°è¯•ä¿®å¤LM Studioæˆªæ–­çš„JSON...")
            
            # å¯»æ‰¾JSONå¼€å§‹
            json_start = text.find('{')
            if json_start == -1:
                return None
            
            json_text = text[json_start:]
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä¸å®Œæ•´çš„å­—ç¬¦ä¸²
            if '"chapter_mood": "' in json_text:
                # æ‰¾åˆ°æœ€åä¸€ä¸ªä¸å®Œæ•´çš„å­—æ®µ
                last_quote_pos = json_text.rfind('"chapter_mood": "')
                if last_quote_pos != -1:
                    # æˆªå–åˆ°è¯¥ä½ç½®ï¼Œç„¶åè¡¥å…¨
                    prefix = json_text[:last_quote_pos + len('"chapter_mood": "')]
                    # è¡¥å…¨å¸¸è§çš„moodå€¼
                    completed_json = prefix + 'è°ƒæ•™æ²‰æ²¦"\n    }\n  ]\n}'
                    
                    # å°è¯•è§£æ
                    try:
                        data = json.loads(completed_json)
                        # ç¡®ä¿æœ‰åŸºæœ¬ç»“æ„
                        if isinstance(data, dict) and 'chapters' in data:
                            # è¡¥å…¨ç¼ºå¤±çš„batch_info
                            if 'batch_info' not in data:
                                chapters = data['chapters']
                                if chapters:
                                    first_chapter = chapters[0].get('chapter_number', 31)
                                    data['batch_info'] = {
                                        "start_chapter": first_chapter,
                                        "end_chapter": first_chapter,
                                        "total_chapters": len(chapters)
                                    }
                            
                            print(f"âœ… LM Studioæˆªæ–­ä¿®å¤æˆåŠŸï¼šç”Ÿæˆäº†{len(data.get('chapters', []))}ç« ")
                            return data
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸ æˆªæ–­ä¿®å¤åJSONä»æ— æ•ˆ: {e}")
                        
            return None
            
        except Exception as e:
            print(f"âš ï¸ LM Studioæˆªæ–­ä¿®å¤å¼‚å¸¸: {e}")
            return None

    def _extract_json_candidates(self, text: str) -> List[str]:
        """æå–å¯èƒ½çš„JSONå†…å®¹å€™é€‰"""
        candidates = []

        # æ¨¡å¼1: Markdownä»£ç å—
        patterns = [
            r'```json\s*(\{.*?\})\s*```',
            r'```\s*(\{.*?\})\s*```',
            r'```json\s*(\[.*?\])\s*```',
            r'```\s*(\[.*?\])\s*```',
        ]

        for pattern in patterns:
            matches = re.findall(pattern, text, re.DOTALL | re.IGNORECASE)
            candidates.extend(matches)

        # æ¨¡å¼2: ç›´æ¥çš„JSONå¯¹è±¡ï¼ˆæ›´å¤æ‚çš„åŒ¹é…ï¼‰
        # å¯»æ‰¾ä»¥{å¼€å§‹ï¼Œä»¥}ç»“æŸçš„å®Œæ•´JSONå¯¹è±¡
        brace_count = 0
        start_pos = -1

        for i, char in enumerate(text):
            if char == '{':
                if brace_count == 0:
                    start_pos = i
                brace_count += 1
            elif char == '}':
                brace_count -= 1
                if brace_count == 0 and start_pos != -1:
                    candidate = text[start_pos:i+1]
                    if len(candidate) > 50:  # è¿‡æ»¤å¤ªçŸ­çš„å†…å®¹
                        candidates.append(candidate)

        # æ¨¡å¼3: å¯»æ‰¾åŒ…å«"chapters"å…³é”®å­—çš„JSONç‰‡æ®µ
        chapter_pattern = r'\{[^{}]*"chapters"[^{}]*\[[^\[\]]*(?:\[[^\[\]]*\][^\[\]]*)*\][^{}]*\}'
        chapter_matches = re.findall(chapter_pattern, text, re.DOTALL)
        candidates.extend(chapter_matches)

        # å»é‡å¹¶æŒ‰é•¿åº¦æ’åºï¼ˆé•¿çš„ä¼˜å…ˆï¼‰
        candidates = list(set(candidates))
        candidates.sort(key=len, reverse=True)

        print(f"ğŸ” æ‰¾åˆ° {len(candidates)} ä¸ªJSONå€™é€‰")
        return candidates

    def _repair_json_content(self, json_str: str) -> Optional[Dict[str, Any]]:
        """ä¿®å¤å•ä¸ªJSONå­—ç¬¦ä¸²"""
        try:
            # ç›´æ¥å°è¯•è§£æ
            return json.loads(json_str)
        except json.JSONDecodeError:
            pass

        # å¼€å§‹ä¿®å¤
        repaired = json_str.strip()

        # ä¿®å¤1: ç§»é™¤å°¾éšé€—å·
        repaired = re.sub(r',\s*([}\]])', r'\1', repaired)

        # ä¿®å¤2: ä¿®å¤æœªå¼•ç”¨çš„é”®å
        repaired = re.sub(r'([{,]\s*)([a-zA-Z_][a-zA-Z0-9_]*)\s*:', r'\1"\2":', repaired)

        # ä¿®å¤3: ä¿®å¤å•å¼•å·
        repaired = repaired.replace("'", '"')

        # ä¿®å¤4: ä¿®å¤æ¢è¡Œç¬¦å’Œç‰¹æ®Šå­—ç¬¦
        repaired = repaired.replace('\n', '\\n').replace('\r', '\\r').replace('\t', '\\t')

        # ä¿®å¤5: ä¿®å¤ä¸å®Œæ•´çš„å­—ç¬¦ä¸²
        repaired = re.sub(r':\s*([^",\[\]{}]+)(?=\s*[,}])', r': "\1"', repaired)

        # ä¿®å¤6: ç¡®ä¿æ•°ç»„å’Œå¯¹è±¡æ­£ç¡®é—­åˆ
        repaired = self._balance_brackets(repaired)

        try:
            return json.loads(repaired)
        except json.JSONDecodeError:
            return None

    def _balance_brackets(self, text: str) -> str:
        """å¹³è¡¡æ‹¬å·å’Œå¤§æ‹¬å·"""
        # è®¡ç®—æ‹¬å·å¹³è¡¡
        brace_count = text.count('{') - text.count('}')
        bracket_count = text.count('[') - text.count(']')

        # æ·»åŠ ç¼ºå¤±çš„é—­åˆæ‹¬å·
        if brace_count > 0:
            text += '}' * brace_count
        if bracket_count > 0:
            text += ']' * bracket_count

        return text

    def _reconstruct_json_from_text(self, text: str) -> Optional[Dict[str, Any]]:
        """ä»æ–‡æœ¬ä¸­æ™ºèƒ½é‡æ„JSONç»“æ„"""
        try:
            # å¯»æ‰¾ç« èŠ‚ä¿¡æ¯
            chapters = []

            # æ¨¡å¼ï¼šå¯»æ‰¾ç« èŠ‚æ ‡é¢˜å’Œæè¿°
            chapter_patterns = [
                r'ç¬¬(\d+)ç« [ï¼š:]\s*([^\n]+)',
                r'ç« èŠ‚\s*(\d+)[ï¼š:]\s*([^\n]+)',
                r'Chapter\s*(\d+)[ï¼š:]\s*([^\n]+)',
            ]

            for pattern in chapter_patterns:
                matches = re.findall(pattern, text, re.IGNORECASE)
                for match in matches:
                    chapter_num = int(match[0])
                    title = match[1].strip()

                    # å¯»æ‰¾å¯¹åº”çš„æè¿°
                    description = self._extract_chapter_description(text, chapter_num, title)

                    chapter_data = {
                        "chapter_number": chapter_num,
                        "title": title,
                        "plot_summary": description or f"ç¬¬{chapter_num}ç« çš„æƒ…èŠ‚å‘å±•",
                        "key_events": [f"{title}ç›¸å…³äº‹ä»¶"],
                        "character_development": "äººç‰©å‘å±•",
                        "chapter_mood": "ç« èŠ‚æ°›å›´"
                    }
                    chapters.append(chapter_data)

            if chapters:
                # æŒ‰ç« èŠ‚å·æ’åº
                chapters.sort(key=lambda x: x["chapter_number"])

                return {
                    "chapters": chapters,
                    "batch_info": {
                        "start_chapter": chapters[0]["chapter_number"],
                        "end_chapter": chapters[-1]["chapter_number"],
                        "total_chapters": len(chapters)
                    }
                }

        except Exception as e:
            print(f"âš ï¸ æ™ºèƒ½é‡æ„å¤±è´¥: {e}")

        return None

    def _extract_chapter_description(self, text: str, chapter_num: int, title: str) -> str:
        """æå–ç« èŠ‚æè¿°"""
        # åœ¨æ ‡é¢˜é™„è¿‘å¯»æ‰¾æè¿°æ–‡æœ¬
        title_pos = text.find(title)
        if title_pos == -1:
            return ""

        # æå–æ ‡é¢˜åçš„ä¸€æ®µæ–‡æœ¬ä½œä¸ºæè¿°
        start = title_pos + len(title)
        end = min(start + 200, len(text))

        description = text[start:end].strip()

        # æ¸…ç†æè¿°æ–‡æœ¬
        description = re.sub(r'\n+', ' ', description)
        description = re.sub(r'\s+', ' ', description)

        return description[:100] if description else f"ç¬¬{chapter_num}ç« çš„å†…å®¹æè¿°"
    
    def generate_with_structured_output(
        self,
        messages: List[Dict[str, str]],
        temperature: float = 0.8
    ) -> Tuple[Optional[Dict[str, Any]], str]:
        """ä½¿ç”¨structured outputç”Ÿæˆæ•…äº‹çº¿"""
        # æ£€æŸ¥æ˜¯å¦æ”¯æŒstructured outputs
        if not self._supports_advanced_features():
            print(f"âš ï¸ å½“å‰æä¾›å•† {self.provider_name.upper()} ä¸æ”¯æŒStructured Outputsï¼Œè·³è¿‡æ­¤æ–¹æ³•")
            return None, f"provider_{self.provider_name}_not_supported_structured_outputs"

        try:
            print(f"ğŸ”§ å°è¯•ä½¿ç”¨{self.provider_name.upper()} Structured Outputsç”Ÿæˆæ•…äº‹çº¿...")
            
            # ä»æç¤ºè¯ä¸­æå–ç« èŠ‚èŒƒå›´ä¿¡æ¯
            expected_count = self._extract_chapter_count_from_messages(messages)
            print(f"ğŸ”¢ æœŸæœ›ç”Ÿæˆç« èŠ‚æ•°: {expected_count}")

            response = self.chatLLM(
                messages=messages,
                temperature=temperature,
                response_format=self.get_storyline_schema(expected_count)
            )
            
            if response.get("content"):
                try:
                    data = json.loads(response["content"])
                    
                    print("âœ… Structured OutputsæˆåŠŸç”ŸæˆJSONæ ¼å¼")
                    # ä½¿ç”¨ç»Ÿä¸€çš„è°ƒè¯•æ–¹æ³•æ£€æŸ¥ç« èŠ‚æ•°é‡
                    self._debug_chapter_count(data, expected_count, "Structured Outputs")
                    
                    return data, "structured_output_success"
                except json.JSONDecodeError as e:
                    print(f"âš ï¸ Structured Outputsè¿”å›å†…å®¹æ— æ³•è§£æ: {e}")
                    print("ğŸ” è°ƒè¯•ä¿¡æ¯ - åŸå§‹å“åº”å†…å®¹:")
                    print("="*80)
                    print(response.get("content", ""))
                    print("="*80)
                    self._save_error_data("structured_output_json_parse_error", messages,
                                        response.get("content", ""), str(e))
                    return None, f"structured_output_json_error: {e}"
            else:
                print("âš ï¸ Structured Outputsæœªè¿”å›å†…å®¹")
                print(f"ğŸ” å®Œæ•´å“åº”: {response}")
                self._save_error_data("structured_output_no_content", messages, "", "No content returned")
                return None, "structured_output_no_content"

        except Exception as e:
            print(f"âŒ Structured Outputsè°ƒç”¨å¤±è´¥: {e}")
            self._save_error_data("structured_output_api_error", messages, "", str(e))
            return None, f"structured_output_error: {e}"
    
    def generate_with_tool_calling(
        self,
        messages: List[Dict[str, str]],
        temperature: float = 0.8
    ) -> Tuple[Optional[Dict[str, Any]], str]:
        """ä½¿ç”¨tool callingç”Ÿæˆæ•…äº‹çº¿"""
        # æ£€æŸ¥æ˜¯å¦æ”¯æŒtool calling
        if not self._supports_tool_calling():
            print(f"âš ï¸ å½“å‰æä¾›å•† {self.provider_name.upper()} ä¸æ”¯æŒTool Callingï¼Œè·³è¿‡æ­¤æ–¹æ³•")
            return None, f"provider_{self.provider_name}_not_supported_tool_calling"

        try:
            print(f"ğŸ”§ å°è¯•ä½¿ç”¨{self.provider_name.upper()} Tool Callingç”Ÿæˆæ•…äº‹çº¿...")
            
            # ä»æç¤ºè¯ä¸­æå–ç« èŠ‚èŒƒå›´ä¿¡æ¯
            expected_count = self._extract_chapter_count_from_messages(messages)
            print(f"ğŸ”¢ æœŸæœ›ç”Ÿæˆç« èŠ‚æ•°: {expected_count}")

            # æ ¹æ®æä¾›å•†è°ƒæ•´tool_choiceæ ¼å¼
            # æ³¨æ„ï¼šLM Studioå·²åœ¨_supports_tool_callingä¸­è¢«ç¦ç”¨ï¼Œæ­¤ä»£ç ä»…ä¸ºå¤‡ç”¨
            if self.provider_name == "lmstudio":
                # LM Studioåªæ”¯æŒå­—ç¬¦ä¸²æ ¼å¼çš„tool_choice
                tool_choice_param = "auto"  # ä½¿ç”¨autoè®©æ¨¡å‹è‡ªåŠ¨é€‰æ‹©å·¥å…·
            else:
                # OpenRouterå’Œå…¶ä»–æä¾›å•†æ”¯æŒå¯¹è±¡æ ¼å¼
                tool_choice_param = {"type": "function", "function": {"name": "generate_storyline_batch"}}
            
            response = self.chatLLM(
                messages=messages,
                temperature=temperature,
                tools=self.get_storyline_tools(expected_count),
                tool_choice=tool_choice_param
            )
            
            if response.get("tool_calls"):
                for tool_call in response["tool_calls"]:
                    if tool_call.function.name == "generate_storyline_batch":
                        # ğŸ” æ£€æµ‹Tool Callingå“åº”æˆªæ–­
                        self._detect_and_display_truncation(tool_call.function.arguments, "Tool Callingå“åº”")
                        
                        try:
                            data = json.loads(tool_call.function.arguments)
                            
                            print("âœ… Tool CallingæˆåŠŸç”ŸæˆJSONæ ¼å¼")
                            # ä½¿ç”¨ç»Ÿä¸€çš„è°ƒè¯•æ–¹æ³•æ£€æŸ¥ç« èŠ‚æ•°é‡
                            self._debug_chapter_count(data, expected_count, "Tool Calling")
                            self._record_success("tool_calling_success")
                            return data, "tool_calling_success"
                        except json.JSONDecodeError as e:
                            print(f"âš ï¸ Tool Callingå‚æ•°æ— æ³•è§£æ: {e}")
                            print("ğŸ” è°ƒè¯•ä¿¡æ¯ - åŸå§‹å‡½æ•°å‚æ•°:")
                            print("="*80)
                            print(tool_call.function.arguments)
                            print("="*80)
                            self._save_error_data("tool_calling_json_parse_error", messages,
                                                tool_call.function.arguments, str(e))
                            return None, f"tool_calling_json_error: {e}"

                print("âš ï¸ Tool Callingæœªè¿”å›é¢„æœŸçš„å‡½æ•°è°ƒç”¨")
                print("ğŸ” è°ƒè¯•ä¿¡æ¯ - å®é™…è¿”å›çš„å·¥å…·è°ƒç”¨:")
                print("="*80)
                for i, tool_call in enumerate(response.get("tool_calls", [])):
                    print(f"å·¥å…·è°ƒç”¨ {i+1}: {tool_call.function.name}")
                    print(f"å‚æ•°: {tool_call.function.arguments[:500]}...")
                print("="*80)
                self._save_error_data("tool_calling_no_expected_function", messages,
                                    str(response.get("tool_calls", [])), "No expected function call")
                return None, "tool_calling_no_expected_function"
            else:
                print("âš ï¸ Tool Callingæœªè¿”å›å·¥å…·è°ƒç”¨")
                print("ğŸ” è°ƒè¯•ä¿¡æ¯ - å®Œæ•´å“åº”:")
                print("="*80)
                print(json.dumps(response, ensure_ascii=False, indent=2))
                print("="*80)
                self._save_error_data("tool_calling_no_tools", messages,
                                    str(response), "No tool calls returned")
                return None, "tool_calling_no_tools"

        except Exception as e:
            print(f"âŒ Tool Callingè°ƒç”¨å¤±è´¥: {e}")
            self._save_error_data("tool_calling_api_error", messages, "", str(e))
            return None, f"tool_calling_error: {e}"
    
    def generate_with_fallback_repair(
        self,
        messages: List[Dict[str, str]],
        temperature: float = 0.8
    ) -> Tuple[Optional[Dict[str, Any]], str]:
        """ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•+å¢å¼ºJSONä¿®å¤ç”Ÿæˆæ•…äº‹çº¿"""
        try:
            print("ğŸ”§ å°è¯•ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•+å¢å¼ºJSONä¿®å¤ç”Ÿæˆæ•…äº‹çº¿...")

            # å¢å¼ºæç¤ºè¯ï¼Œæé«˜JSONæ ¼å¼æ­£ç¡®ç‡
            enhanced_messages = self._enhance_json_prompt(messages.copy())

            for retry in range(self.max_retries + 1):
                print(f"ğŸ”„ ç¬¬{retry+1}æ¬¡å°è¯•ç”Ÿæˆ...")

                # æ ¹æ®é‡è¯•æ¬¡æ•°è°ƒæ•´ç­–ç•¥
                current_messages = enhanced_messages.copy()
                if retry > 0:
                    current_messages = self._add_retry_instructions(current_messages, retry)

                response = self.chatLLM(
                    messages=current_messages,
                    temperature=max(0.3, temperature - retry * 0.1)  # é‡è¯•æ—¶é™ä½æ¸©åº¦
                )

                if response.get("content"):
                    print(f"ğŸ“ æ”¶åˆ°å“åº”ï¼Œé•¿åº¦: {len(response['content'])}å­—ç¬¦")

                    # ğŸ” æ£€æµ‹æˆªæ–­
                    self._detect_and_display_truncation(response["content"], f"ä¼ ç»Ÿæ–¹æ³•(ç¬¬{retry+1}æ¬¡å°è¯•)")

                    # å°è¯•ç›´æ¥è§£æ
                    try:
                        data = json.loads(response["content"])
                        if self._validate_storyline_structure(data):
                            print(f"âœ… ä¼ ç»Ÿæ–¹æ³•ç¬¬{retry+1}æ¬¡å°è¯•æˆåŠŸ")
                            # ä»æ¶ˆæ¯ä¸­æå–æœŸæœ›ç« èŠ‚æ•°ä»¥ä¾¿è°ƒè¯•
                            expected_count = self._extract_chapter_count_from_messages(messages)
                            self._debug_chapter_count(data, expected_count, f"ä¼ ç»Ÿæ–¹æ³•(ç¬¬{retry+1}æ¬¡)")
                            self._record_success(f"traditional_success_attempt_{retry+1}")
                            return data, f"traditional_success_attempt_{retry+1}"
                        else:
                            print(f"âš ï¸ JSONæ ¼å¼æ­£ç¡®ä½†ç»“æ„ä¸ç¬¦åˆè¦æ±‚")
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸ JSONè§£æå¤±è´¥: {e}")
                        # ä¿å­˜JSONè§£æé”™è¯¯æ•°æ®
                        self._save_error_data("json_parse_error", current_messages,
                                            response["content"], str(e), retry + 1)

                    # å°è¯•å¢å¼ºä¿®å¤
                    print("ğŸ”§ å¼€å§‹å¢å¼ºJSONä¿®å¤...")
                    fixed_data = self.fix_json_format(response["content"])
                    if fixed_data and self._validate_storyline_structure(fixed_data):
                        print(f"âœ… å¢å¼ºJSONä¿®å¤æˆåŠŸï¼Œç¬¬{retry+1}æ¬¡å°è¯•")
                        # ä»æ¶ˆæ¯ä¸­æå–æœŸæœ›ç« èŠ‚æ•°ä»¥ä¾¿è°ƒè¯•
                        expected_count = self._extract_chapter_count_from_messages(messages)
                        self._debug_chapter_count(fixed_data, expected_count, f"å¢å¼ºJSONä¿®å¤(ç¬¬{retry+1}æ¬¡)")
                        # è®°å½•æˆåŠŸæ¡ˆä¾‹
                        self._log_successful_generation("enhanced_json_repair", retry + 1, fixed_data)
                        self._record_success("enhanced_json_repair")
                        return fixed_data, f"enhanced_json_repair_success_attempt_{retry+1}"
                    else:
                        print(f"âŒ ç¬¬{retry+1}æ¬¡å°è¯•å¢å¼ºJSONä¿®å¤å¤±è´¥")
                        # ä¿å­˜ä¿®å¤å¤±è´¥çš„æ•°æ®
                        self._save_error_data("json_repair_failed", current_messages,
                                            response["content"], "JSON repair and validation failed", retry + 1)
                else:
                    print(f"âš ï¸ ç¬¬{retry+1}æ¬¡å°è¯•æœªè¿”å›å†…å®¹")
                    # ä¿å­˜æ— å†…å®¹é”™è¯¯
                    self._save_error_data("no_content_returned", current_messages,
                                        "", "API returned no content", retry + 1)

            # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œä¿å­˜æœ€ç»ˆå¤±è´¥ä¿¡æ¯
            self._save_error_data("all_attempts_failed", enhanced_messages,
                                "", f"All {self.max_retries + 1} attempts failed")
            return None, f"all_enhanced_attempts_failed_after_{self.max_retries + 1}_tries"

        except Exception as e:
            print(f"âŒ å¢å¼ºä¼ ç»Ÿæ–¹æ³•è°ƒç”¨å¤±è´¥: {e}")
            return None, f"enhanced_traditional_error: {e}"

    def _enhance_json_prompt(self, messages: List[Dict[str, str]]) -> List[Dict[str, str]]:
        """å¢å¼ºæç¤ºè¯ä»¥æé«˜JSONæ ¼å¼æ­£ç¡®ç‡"""
        if not messages:
            return messages

        # åœ¨æœ€åä¸€ä¸ªç”¨æˆ·æ¶ˆæ¯åæ·»åŠ JSONæ ¼å¼è¦æ±‚
        last_message = messages[-1]["content"]

        json_instructions = """

**é‡è¦ï¼šè¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–å…¶ä»–æ–‡æœ¬ï¼š**

```json
{
  "chapters": [
    {
      "chapter_number": 1,
      "title": "ç« èŠ‚æ ‡é¢˜",
      "plot_summary": "è¯¦ç»†çš„æƒ…èŠ‚æ¢—æ¦‚ï¼Œè‡³å°‘50å­—",
      "key_events": ["å…³é”®äº‹ä»¶1", "å…³é”®äº‹ä»¶2", "å…³é”®äº‹ä»¶3"],
      "character_development": "äººç‰©å‘å±•æè¿°",
      "chapter_mood": "ç« èŠ‚æƒ…ç»ªæ°›å›´"
    }
  ],
  "batch_info": {
    "start_chapter": 1,
    "end_chapter": 1,
    "total_chapters": 1
  }
}
```

**æ ¼å¼è¦æ±‚ï¼š**
1. åªè¿”å›JSONï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæ–‡å­—
2. ç¡®ä¿æ‰€æœ‰å­—ç¬¦ä¸²éƒ½ç”¨åŒå¼•å·åŒ…å›´
3. ç¡®ä¿æ‰€æœ‰æ‹¬å·å’Œå¤§æ‹¬å·æ­£ç¡®é…å¯¹
4. ä¸è¦åœ¨æœ€åä¸€ä¸ªå…ƒç´ åæ·»åŠ é€—å·
5. key_eventså¿…é¡»æ˜¯å­—ç¬¦ä¸²æ•°ç»„ï¼Œè‡³å°‘åŒ…å«3ä¸ªäº‹ä»¶"""

        messages[-1]["content"] = last_message + json_instructions
        return messages

    def _add_retry_instructions(self, messages: List[Dict[str, str]], retry_count: int) -> List[Dict[str, str]]:
        """æ ¹æ®é‡è¯•æ¬¡æ•°æ·»åŠ ç‰¹å®šæŒ‡ä»¤"""
        retry_instructions = {
            1: "\n\n**æ³¨æ„ï¼šä¸Šæ¬¡è¿”å›çš„JSONæ ¼å¼æœ‰é—®é¢˜ï¼Œè¯·ç¡®ä¿è¿”å›ä¸¥æ ¼çš„JSONæ ¼å¼ï¼Œä¸è¦åŒ…å«ä»»ä½•markdownæ ‡è®°æˆ–è§£é‡Šæ–‡å­—ã€‚**",
            2: "\n\n**æœ€åä¸€æ¬¡æœºä¼šï¼šè¯·åªè¿”å›çº¯JSONå¯¹è±¡ï¼Œä»{å¼€å§‹ï¼Œä»¥}ç»“æŸï¼Œä¸­é—´ä¸è¦æœ‰ä»»ä½•å…¶ä»–å†…å®¹ã€‚**"
        }

        if retry_count in retry_instructions:
            messages[-1]["content"] += retry_instructions[retry_count]

        return messages

    def _validate_storyline_structure(self, data: Dict[str, Any]) -> bool:
        """éªŒè¯æ•…äº‹çº¿æ•°æ®ç»“æ„æ˜¯å¦æ­£ç¡®"""
        try:
            # æ£€æŸ¥å¿…éœ€çš„é¡¶çº§é”®
            if not isinstance(data, dict):
                return False

            if "chapters" not in data:
                print("âŒ ç¼ºå°‘ 'chapters' é”®")
                return False

            chapters = data["chapters"]
            if not isinstance(chapters, list) or len(chapters) == 0:
                print("âŒ 'chapters' å¿…é¡»æ˜¯éç©ºæ•°ç»„")
                return False

            # æ£€æŸ¥æ¯ä¸ªç« èŠ‚çš„ç»“æ„
            for i, chapter in enumerate(chapters):
                if not isinstance(chapter, dict):
                    print(f"âŒ ç« èŠ‚ {i+1} ä¸æ˜¯å¯¹è±¡")
                    return False

                required_fields = ["chapter_number", "title", "plot_summary"]
                for field in required_fields:
                    if field not in chapter:
                        print(f"âŒ ç« èŠ‚ {i+1} ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                        return False

                # æ£€æŸ¥å­—æ®µç±»å‹
                if not isinstance(chapter["chapter_number"], int):
                    print(f"âŒ ç« èŠ‚ {i+1} çš„ chapter_number å¿…é¡»æ˜¯æ•´æ•°")
                    return False

                if not isinstance(chapter["title"], str) or not chapter["title"].strip():
                    print(f"âŒ ç« èŠ‚ {i+1} çš„ title å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²")
                    return False

                if not isinstance(chapter["plot_summary"], str) or len(chapter["plot_summary"].strip()) < 10:
                    print(f"âŒ ç« èŠ‚ {i+1} çš„ plot_summary å¿…é¡»æ˜¯è‡³å°‘10å­—ç¬¦çš„å­—ç¬¦ä¸²")
                    return False

            print("âœ… æ•…äº‹çº¿ç»“æ„éªŒè¯é€šè¿‡")
            return True

        except Exception as e:
            print(f"âŒ ç»“æ„éªŒè¯å‡ºé”™: {e}")
            return False
    
    def generate_storyline_batch(
        self,
        messages: List[Dict[str, str]],
        temperature: float = 0.8
    ) -> Tuple[Optional[Dict[str, Any]], str]:
        """
        ç”Ÿæˆæ•…äº‹çº¿æ‰¹æ¬¡ï¼ŒæŒ‰ä¼˜å…ˆçº§å°è¯•ä¸åŒæ–¹æ³•ï¼š
        1. OpenRouter Structured Outputs (ä»…OpenRouter)
        2. OpenRouter Tool Calling (ä»…OpenRouter)
        3. ä¼ ç»Ÿæ–¹æ³• + JSONä¿®å¤ï¼ˆé‡è¯•2æ¬¡ï¼‰
        """

        print(f"ğŸ”§ å½“å‰æä¾›å•†: {self.provider_name.upper()}")

        # æ–¹æ³•1: Structured Outputs (ä»…OpenRouter)
        if self._supports_advanced_features():
            data, status = self.generate_with_structured_output(messages, temperature)
            if data:
                self._log_successful_generation("structured_output", 1, data)
                return data, status

        # æ–¹æ³•2: Tool Calling (OpenRouterå’ŒLM Studio)
        if self._supports_tool_calling():
            data, status = self.generate_with_tool_calling(messages, temperature)
            if data:
                self._log_successful_generation("tool_calling", 1, data)
                return data, status
        else:
            print(f"ğŸ”§ {self.provider_name.upper()} ä¸æ”¯æŒTool Callingï¼Œè·³è¿‡æ­¤æ–¹æ³•")

        # æ–¹æ³•3: ä¼ ç»Ÿæ–¹æ³• + JSONä¿®å¤ï¼ˆæ‰€æœ‰æä¾›å•†éƒ½æ”¯æŒï¼‰
        data, status = self.generate_with_fallback_repair(messages, temperature)
        if data:
            # æˆåŠŸæ¡ˆä¾‹å·²åœ¨ generate_with_fallback_repair ä¸­è®°å½•
            return data, status

        # æ–¹æ³•4: æ¸è¿›å¼ç”Ÿæˆï¼ˆé’ˆå¯¹LM Studioç­‰å®¹æ˜“æˆªæ–­çš„æä¾›å•†ï¼‰
        print("ğŸ”„ æ‰€æœ‰æ ‡å‡†æ–¹æ³•å¤±è´¥ï¼Œå°è¯•æ¸è¿›å¼ç”Ÿæˆç­–ç•¥...")
        expected_count = self._extract_chapter_count_from_messages(messages)
        if expected_count > 3:  # åªæœ‰åœ¨è¯·æ±‚è¾ƒå¤šç« èŠ‚æ—¶æ‰ä½¿ç”¨æ¸è¿›å¼ç­–ç•¥
            data, status = self._attempt_progressive_generation(messages, expected_count)
            if data:
                print(f"âœ… æ¸è¿›å¼ç”ŸæˆæˆåŠŸï¼š{status}")
                return data, status

        # æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œä¿å­˜æœ€ç»ˆå¤±è´¥ä¿¡æ¯
        print("âŒ æ‰€æœ‰JSONç”Ÿæˆæ–¹æ³•éƒ½å¤±è´¥ï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡")
        self._save_error_data("all_methods_failed", messages, "", "All generation methods failed")
        return None, "all_methods_failed"
    
    def _attempt_progressive_generation(self, messages: List[Dict[str, str]], expected_count: int) -> Tuple[Optional[Dict[str, Any]], str]:
        """æ¸è¿›å¼ç”Ÿæˆï¼šå¦‚æœ10ç« å¤±è´¥ï¼Œå°è¯•5ç« ï¼Œå¦‚æœ5ç« å¤±è´¥ï¼Œå°è¯•3ç« """
        print("ğŸ”„ å¼€å§‹æ¸è¿›å¼ç”Ÿæˆç­–ç•¥...")
        
        # ä»æ¶ˆæ¯ä¸­æå–ç« èŠ‚èŒƒå›´ä¿¡æ¯
        original_messages = messages.copy()
        
        # å°è¯•ä¸åŒçš„ç« èŠ‚æ•°é‡
        attempt_sizes = [5, 3, 1] if expected_count > 5 else [3, 1] if expected_count > 3 else [1]
        
        for attempt_size in attempt_sizes:
            print(f"ğŸ”„ å°è¯•ç”Ÿæˆ{attempt_size}ç« ï¼ˆåŸè®¡åˆ’{expected_count}ç« ï¼‰...")
            
            # ä¿®æ”¹æ¶ˆæ¯ä»¥è¯·æ±‚æ›´å°‘çš„ç« èŠ‚
            modified_messages = self._modify_messages_for_smaller_batch(original_messages, attempt_size)
            
            # å°è¯•æ‰€æœ‰ç”Ÿæˆæ–¹æ³•
            for method_name, method_func in [
                ("Tool Calling", self.generate_with_tool_calling),
                ("JSONä¿®å¤", self.generate_with_fallback_repair)
            ]:
                if method_name == "Tool Calling" and not self._supports_tool_calling():
                    continue
                    
                print(f"ğŸ”§ {method_name}æ–¹å¼ç”Ÿæˆ{attempt_size}ç« ...")
                try:
                    data, status = method_func(modified_messages, 0.7)  # é™ä½æ¸©åº¦æé«˜ç¨³å®šæ€§
                    if data and self._validate_storyline_structure(data):
                        chapter_count = len(data.get('chapters', []))
                        print(f"âœ… æ¸è¿›å¼ç”ŸæˆæˆåŠŸ: {method_name}æ–¹å¼ç”Ÿæˆäº†{chapter_count}ç« ")
                        result_status = f"progressive_{method_name.lower().replace(' ', '_')}_success_{attempt_size}chapters"
                        self._record_success(result_status)
                        return data, result_status
                except Exception as e:
                    print(f"âš ï¸ {method_name}æ–¹å¼å¤±è´¥: {e}")
                    continue
        
        print("âŒ æ‰€æœ‰æ¸è¿›å¼ç”Ÿæˆå°è¯•éƒ½å¤±è´¥")
        return None, "progressive_generation_failed"
    
    def _modify_messages_for_smaller_batch(self, messages: List[Dict[str, str]], target_count: int) -> List[Dict[str, str]]:
        """ä¿®æ”¹æ¶ˆæ¯å†…å®¹ä»¥è¯·æ±‚æ›´å°‘çš„ç« èŠ‚"""
        modified_messages = []
        
        for message in messages:
            if message.get("role") == "user":
                content = message["content"]
                # ç®€åŒ–æç¤ºè¯ï¼Œå‡å°‘tokenæ¶ˆè€—
                simplified_content = self._simplify_prompt_for_fewer_chapters(content, target_count)
                modified_messages.append({
                    "role": "user", 
                    "content": simplified_content
                })
            else:
                modified_messages.append(message)
        
        return modified_messages
    
    def _simplify_prompt_for_fewer_chapters(self, original_content: str, target_count: int) -> str:
        """ç®€åŒ–æç¤ºè¯ï¼Œå‡å°‘tokenæ¶ˆè€—ï¼Œæé«˜æˆåŠŸç‡"""
        
        # æå–å…³é”®ä¿¡æ¯
        key_info = {}
        lines = original_content.split('\n')
        
        # æå–å…³é”®ç« èŠ‚èŒƒå›´ä¿¡æ¯
        for line in lines:
            if "ç« èŠ‚èŒƒå›´:" in line:
                key_info["ç« èŠ‚èŒƒå›´"] = line
            elif line.startswith("**å¤§çº²:**"):
                # æå–å¤§çº²çš„å…³é”®éƒ¨åˆ†ï¼ˆåªä¿ç•™ç›¸å…³ç« èŠ‚ï¼‰
                key_info["å¤§çº²"] = "**å¤§çº²:** ç»è¿‡è°ƒæ•™ï¼ŒæŸ³å¦‚çƒŸå½»åº•æ²¦ä¸ºæ€§å¥´ï¼Œæ­£åœ¨è¿›è¡Œæ¯ç‹—å…»æˆè®­ç»ƒã€‚"
            elif line.startswith("**äººç‰©åˆ—è¡¨:**"):
                key_info["äººç‰©åˆ—è¡¨"] = "**äººç‰©åˆ—è¡¨:** æ—æµ©(ä¸»è§’), æŸ³å¦‚çƒŸ(æ±Ÿå—åå¦“, æ€§å¥´)"
            elif line.startswith("**å†™ä½œè¦æ±‚:**"):
                key_info["å†™ä½œè¦æ±‚"] = "**å†™ä½œè¦æ±‚:** é‡ç‚¹æ€§çˆ±æå†™ï¼Œçˆ½æ–‡é£æ ¼ï¼Œç›´ç™½éœ²éª¨"
            elif "å‰ç½®æ•…äº‹çº¿:" in line:
                key_info["å‰ç½®æ•…äº‹çº¿"] = line
        
        # æ„å»ºç®€åŒ–çš„æç¤ºè¯
        simplified_prompt = f"""
è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼ç”Ÿæˆ{target_count}ç« æ•…äº‹çº¿ï¼š

{key_info.get('å¤§çº²', '')}
{key_info.get('äººç‰©åˆ—è¡¨', '')}
{key_info.get('å†™ä½œè¦æ±‚', '')}

**è¦æ±‚ç”Ÿæˆç¬¬31-{30+target_count}ç« ï¼Œå…±{target_count}ç« **

å¿…é¡»è¿”å›å®Œæ•´JSONæ ¼å¼ï¼š
```json
{{
  "chapters": [
    {{
      "chapter_number": 31,
      "title": "ç« èŠ‚æ ‡é¢˜",  
      "plot_summary": "è¯¦ç»†å‰§æƒ…æ¢—æ¦‚ï¼Œè‡³å°‘50å­—",
      "key_events": ["äº‹ä»¶1", "äº‹ä»¶2", "äº‹ä»¶3"],
      "character_development": "äººç‰©å‘å±•æè¿°",
      "chapter_mood": "æƒ…ç»ªæ°›å›´"
    }}
  ],
  "batch_info": {{
    "start_chapter": 31,
    "end_chapter": {30+target_count},
    "total_chapters": {target_count}
  }}
}}
```

**å…³é”®è¦æ±‚ï¼š**
1. åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—
2. ç¡®ä¿ç”Ÿæˆ{target_count}ç« å®Œæ•´å†…å®¹
3. ç¡®ä¿JSONè¯­æ³•æ­£ç¡®
4. æ¯ç« éƒ½è¦æœ‰å®Œæ•´çš„å­—æ®µ
"""
        
        return simplified_prompt
    
    def _detect_and_display_truncation(self, content: str, source: str = "æœªçŸ¥æ¥æº"):
        """æ£€æµ‹å¹¶åœ¨æ§åˆ¶å°æ˜¾ç¤ºæˆªæ–­ä¿¡æ¯"""
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨æˆªæ–­æ£€æµ‹
        if not self.truncation_detection.get("enabled", True):
            return
        
        self.stats["total_attempts"] += 1
        
        if not content:
            print(f"âš ï¸ {source}: å†…å®¹ä¸ºç©º")
            return
        
        content_length = len(content)
        print(f"ğŸ“ {source}: å†…å®¹é•¿åº¦ {content_length} å­—ç¬¦")
        
        # å¤šç§æˆªæ–­æ£€æµ‹æ–¹æ³•
        truncation_indicators = self._analyze_truncation_patterns(content)
        
        if truncation_indicators["is_truncated"]:
            self.stats["truncation_detected"] += 1
            print(f"ğŸš¨ æ£€æµ‹åˆ°{source}å¯èƒ½è¢«æˆªæ–­ï¼")
            print("="*60)
            
            if self.truncation_detection.get("show_detailed_analysis", True):
                print("ğŸ“Š æˆªæ–­åˆ†æç»“æœ:")
                for indicator, details in truncation_indicators.items():
                    if indicator != "is_truncated" and details:
                        print(f"   â€¢ {indicator}: {details}")
            
            # æ˜¾ç¤ºæˆªæ–­ä½ç½®çš„ä¸Šä¸‹æ–‡
            self._display_truncation_context(content, source)
            print("="*60)
        else:
            print(f"âœ… {source}: æœªæ£€æµ‹åˆ°æ˜æ˜¾æˆªæ–­")
    
    def _analyze_truncation_patterns(self, content: str) -> Dict[str, Any]:
        """åˆ†æå„ç§æˆªæ–­æ¨¡å¼"""
        indicators = {"is_truncated": False}
        
        # 1. JSONç»“æ„ä¸å®Œæ•´
        if content.strip().startswith('{') or content.strip().startswith('['):
            try:
                json.loads(content)
                indicators["json_structure"] = "å®Œæ•´"
            except json.JSONDecodeError as e:
                indicators["is_truncated"] = True
                indicators["json_structure"] = f"ä¸å®Œæ•´ - {str(e)}"
        
        # 2. å­—ç¬¦ä¸²æœªé—­åˆï¼ˆä½†æ’é™¤æ­£å¸¸çš„å•ä¸ªå­—ç¬¦ç»“å°¾ï¼‰
        unquoted_patterns = [
            r'"[^"]{2,}$',  # ä»¥æœªé—­åˆå¼•å·ç»“å°¾ï¼Œä¸”å†…å®¹é•¿åº¦>2
            r'"[^"]*\n\s*$',  # ä»¥æœªé—­åˆå¼•å·+æ¢è¡Œç»“å°¾
        ]
        
        for pattern in unquoted_patterns:
            if re.search(pattern, content):
                # é¢å¤–æ£€æŸ¥ï¼šç¡®ä¿ä¸æ˜¯æ­£å¸¸ç»“å°¾ï¼ˆå¦‚å•ä¸ªå­—ç¬¦ '}' æˆ– ']'ï¼‰
                last_line = content.strip().split('\n')[-1].strip()
                if not re.match(r'^[\}\]]+$', last_line):  # ä¸åªæ˜¯æ‹¬å·
                    indicators["is_truncated"] = True
                    indicators["unclosed_string"] = "æ£€æµ‹åˆ°æœªé—­åˆå­—ç¬¦ä¸²"
                    break
        
        # 3. å¸¸è§æˆªæ–­ä½ç½®æ£€æµ‹
        truncation_positions = [
            r'"chapter_mood":\s*"[^"]*$',  # chapter_moodå­—æ®µæˆªæ–­
            r'"plot_summary":\s*"[^"]*$',  # plot_summaryå­—æ®µæˆªæ–­
            r'"title":\s*"[^"]*$',  # titleå­—æ®µæˆªæ–­
            r'"key_events":\s*\[[^\]]*$',  # key_eventsæ•°ç»„æˆªæ–­
        ]
        
        for i, pattern in enumerate(truncation_positions):
            if re.search(pattern, content):
                indicators["is_truncated"] = True
                indicators[f"field_truncation"] = f"å­—æ®µ{i+1}è¢«æˆªæ–­"
                break
        
        # 4. æ‹¬å·ä¸åŒ¹é…
        open_braces = content.count('{')
        close_braces = content.count('}')
        open_brackets = content.count('[')
        close_brackets = content.count(']')
        
        if open_braces != close_braces or open_brackets != close_brackets:
            indicators["is_truncated"] = True
            indicators["bracket_mismatch"] = f"å¤§æ‹¬å· {open_braces}:{close_braces}, ä¸­æ‹¬å· {open_brackets}:{close_brackets}"
        
        # 5. å†…å®¹é•¿åº¦å¼‚å¸¸çŸ­
        if content.strip().endswith(('","', '",', '"')):
            last_line = content.strip().split('\n')[-1]
            if len(last_line) < 50:  # æœ€åä¸€è¡Œå¼‚å¸¸çŸ­
                indicators["is_truncated"] = True
                indicators["short_ending"] = f"æœ€åä¸€è¡Œè¿‡çŸ­: '{last_line}'"
        
        return indicators
    
    def _display_truncation_context(self, content: str, source: str):
        """æ˜¾ç¤ºæˆªæ–­ä½ç½®çš„ä¸Šä¸‹æ–‡"""
        lines = content.split('\n')
        total_lines = len(lines)
        
        print(f"ğŸ“ {source} æˆªæ–­ä¸Šä¸‹æ–‡ (æ€»å…±{total_lines}è¡Œ):")
        
        # æ˜¾ç¤ºæœ€åå‡ è¡Œçš„å†…å®¹
        context_lines = min(self.truncation_detection.get("show_context_lines", 5), total_lines)
        start_line = max(0, total_lines - context_lines)
        
        for i in range(start_line, total_lines):
            line_number = i + 1
            line_content = lines[i].rstrip()
            
            # é«˜äº®æœ€åä¸€è¡Œï¼ˆå¯èƒ½çš„æˆªæ–­ä½ç½®ï¼‰
            if i == total_lines - 1:
                print(f"   -> {line_number:3d}: {line_content} âš ï¸ å¯èƒ½çš„æˆªæ–­ä½ç½®")
            else:
                print(f"      {line_number:3d}: {line_content}")
        
        # åˆ†ææœ€åä¸€è¡Œçš„å…·ä½“æƒ…å†µ
        last_line = lines[-1].rstrip() if lines else ""
        if last_line:
            print(f"ğŸ” æœ€åä¸€è¡Œè¯¦ç»†ä¿¡æ¯:")
            print(f"   â€¢ é•¿åº¦: {len(last_line)} å­—ç¬¦")
            print(f"   â€¢ å†…å®¹: '{last_line}'")
            print(f"   â€¢ ä»¥...ç»“å°¾: {repr(last_line[-10:])}")
        
        # æ£€æŸ¥å­—ç¬¦ç¼–ç é—®é¢˜
        try:
            last_line.encode('utf-8')
            print(f"   â€¢ UTF-8ç¼–ç : æ­£å¸¸")
        except UnicodeEncodeError:
            print(f"   â€¢ UTF-8ç¼–ç : å¯èƒ½æœ‰é—®é¢˜")
    
    def _extract_chapter_count_from_messages(self, messages: List[Dict[str, str]]) -> int:
        """ä»æ¶ˆæ¯ä¸­æå–æœŸæœ›çš„ç« èŠ‚æ•°é‡"""
        for message in messages:
            if message.get("role") == "user" and "content" in message:
                content = message["content"]
                
                # å¯»æ‰¾ç« èŠ‚èŒƒå›´æŒ‡ç¤º
                range_patterns = [
                    r"ç¬¬(\d+)-(\d+)ç« ",  # ç¬¬31-40ç« 
                    r"(\d+)-(\d+)ç« ",    # 31-40ç« 
                    r"ç« èŠ‚èŒƒå›´.*?(\d+)-(\d+)",  # ç« èŠ‚èŒƒå›´: 31-40
                    r"ç”Ÿæˆ(\d+)ç« ",      # ç”Ÿæˆ10ç« 
                ]
                
                for pattern in range_patterns:
                    matches = re.search(pattern, content)
                    if matches:
                        if len(matches.groups()) == 2:
                            start, end = int(matches.group(1)), int(matches.group(2))
                            return end - start + 1
                        elif len(matches.groups()) == 1:
                            return int(matches.group(1))
                
                # å¦‚æœæ‰¾ä¸åˆ°æ˜ç¡®çš„èŒƒå›´ï¼Œé»˜è®¤è¿”å›10
                if "ç¬¬31ç« åˆ°ç¬¬40ç« " in content or "31-40ç« " in content:
                    return 10
                elif "ç”Ÿæˆå®Œæ•´çš„10ç« " in content:
                    return 10
        
        return 10  # é»˜è®¤å€¼