#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
åŠ¨æ€é…ç½®ç®¡ç†å™¨
è´Ÿè´£è¿è¡Œæ—¶åŠ¨æ€ç®¡ç†AIæä¾›å•†é…ç½®ï¼Œæ”¯æŒé€šè¿‡Webç•Œé¢å®æ—¶æ›´æ–°è®¾ç½®
"""

import json
import os
from typing import Dict, Any, List, Optional
from dataclasses import dataclass, asdict
import threading
import time
try:
    from model_fetcher import ModelFetcher
except ImportError:
    ModelFetcher = None

@dataclass
class ProviderConfig:
    """AIæä¾›å•†é…ç½®"""
    name: str
    api_key: str
    model_name: str
    base_url: Optional[str] = None
    models: List[str] = None
    system_prompt: str = ""
    provider_routing: Optional[Dict[str, Any]] = None  # OpenRouter provider routingé…ç½®
    
    def __post_init__(self):
        if self.models is None:
            self.models = []
        if self.provider_routing is None:
            self.provider_routing = {}

# æä¾›å•†æ˜¾ç¤ºåç§°æ˜ å°„ï¼ˆç”¨äºç•Œé¢æ˜¾ç¤ºï¼‰
PROVIDER_DISPLAY_NAMES = {
    "deepseek": "DeepSeek",
    "ali": "Ali (é˜¿é‡Œäº‘)",
    "lmstudio": "LM Studio",
    "gemini": "Gemini",
    "openrouter": "OpenRouter",
    "claude": "Claude",
    "grok": "Grok",
    "fireworks": "Fireworks",
    "lambda": "OpenAIå…¼å®¹æ¨¡å¼"  # Lambda æ˜¾ç¤ºä¸º OpenAIå…¼å®¹æ¨¡å¼
}

class DynamicConfigManager:
    """åŠ¨æ€é…ç½®ç®¡ç†å™¨"""
    
    def __init__(self):
        self._config_lock = threading.RLock()  # ä½¿ç”¨RLockæ”¯æŒé‡å…¥
        self._current_provider = "deepseek"
        self._providers = {}
        self._debug_level = "1"  # é»˜è®¤è°ƒè¯•çº§åˆ«
        self._json_auto_repair = True  # é»˜è®¤å¼€å¯JSONè‡ªåŠ¨ä¿®å¤
        self._cosyvoice_mode = False  # é»˜è®¤å…³é—­CosyVoice2æ¨¡å¼
        self._tts_provider = ""  # TTSå¤„ç†ä¸“ç”¨æä¾›å•†ï¼Œç©ºè¡¨ç¤ºä½¿ç”¨å½“å‰æä¾›å•†
        self._tts_model = ""  # TTSå¤„ç†ä¸“ç”¨æ¨¡å‹ï¼Œç©ºè¡¨ç¤ºä½¿ç”¨å½“å‰æ¨¡å‹
        self._tts_api_key = ""  # TTSå¤„ç†ä¸“ç”¨APIå¯†é’¥ï¼Œç©ºè¡¨ç¤ºä½¿ç”¨å½“å‰APIå¯†é’¥
        self._tts_base_url = ""  # TTSå¤„ç†ä¸“ç”¨åŸºç¡€URLï¼Œç©ºè¡¨ç¤ºä½¿ç”¨å½“å‰åŸºç¡€URL
        self._load_default_configs()
        # å°è¯•ä»æ–‡ä»¶åŠ è½½é…ç½®
        self.load_config_from_file()
    
    def _load_default_configs(self):
        """åŠ è½½é»˜è®¤é…ç½®"""
        # é»˜è®¤æ”¯æŒçš„æä¾›å•†å’Œæ¨¡å‹
        default_configs = {
            "deepseek": ProviderConfig(
                name="deepseek",
                api_key="your-deepseek-api-key-here",
                model_name="deepseek-chat",
                base_url="https://api.deepseek.com",
                models=["deepseek-chat", "deepseek-reasoner"]
            ),
            "ali": ProviderConfig(
                name="ali",
                api_key="your-ali-api-key-here", 
                model_name="qwen-long",
                base_url=None,
                models=["qwen-long", "qwen-plus", "qwen-turbo", "qwen-max"]
            ),
            # "zhipu": ProviderConfig(
            #     name="zhipu",
            #     api_key="your-zhipu-api-key-here",
            #     model_name="glm-4",
            #     base_url=None,
            #     models=["glm-4", "glm-3-turbo", "glm-4-flash"]
            # ),
            "lmstudio": ProviderConfig(
                name="lmstudio",
                api_key="lm-studio",
                model_name="your-local-model-name",
                base_url="http://localhost:1234/v1",
                models=["your-local-model-name"]
            ),
            "gemini": ProviderConfig(
                name="gemini",
                api_key="your-gemini-api-key-here",
                model_name="gemini-pro",
                base_url=None,
                models=["gemini-pro", "gemini-pro-vision", "gemini-1.5-pro", "gemini-1.5-flash"]
            ),
            "openrouter": ProviderConfig(
                name="openrouter",
                api_key="your-openrouter-api-key-here",
                model_name="openai/gpt-4",
                base_url="https://openrouter.ai/api/v1",
                models=[
                    "openai/gpt-4", "openai/gpt-4-turbo", "openai/gpt-3.5-turbo",
                    "deepseek/deepseek-chat", "deepseek/deepseek-coder", "deepseek/deepseek-r1",
                    "google/gemini-pro", "google/gemini-1.5-pro", "google/gemini-2.0-flash-exp",
                    "qwen/qwen-2.5-72b-instruct", "qwen/qwen-2-72b-instruct", "qwen/qwen3-32b", "qwen/qwen3-14b",
                    "grok/grok-beta", "x-ai/grok-beta", "meta-llama/llama-3.3-70b-instruct"
                ],
                provider_routing={
                    # ä¼˜å…ˆä½¿ç”¨æ”¯æŒfp8é‡åŒ–çš„æä¾›å•†ä»¥è·å¾—æœ€ä½³æ€§èƒ½
                    "order": ["novita", "Lambda", "DeepInfra"],
                    "allow_fallbacks": True,  # å…è®¸å›é€€åˆ°å…¶ä»–æä¾›å•†
                    "sort": "throughput",  # ä¼˜å…ˆæŒ‰ååé‡æ’åºï¼Œfp8é‡åŒ–æä¾›å•†é€šå¸¸æœ‰æ›´é«˜ååé‡
                    "quantizations": ["fp8"]  # é¦–é€‰fp8é‡åŒ–ï¼ˆå¦‚æœæä¾›å•†æ”¯æŒï¼‰
                }
            ),
            "claude": ProviderConfig(
                name="claude",
                api_key="your-claude-api-key-here",
                model_name="claude-3-sonnet-20240229",
                base_url="https://api.anthropic.com",
                models=[
                    "claude-3-opus-20240229", "claude-3-sonnet-20240229", 
                    "claude-3-haiku-20240307", "claude-3-5-sonnet-20241022"
                ]
            ),
            "grok": ProviderConfig(
                name="grok",
                api_key="your-grok-api-key-here",
                model_name="grok-3-mini",
                base_url="https://api.x.ai/v1",
                models=[
                    "grok-3-mini", "grok-beta", "grok-vision-beta"
                ]
            ),
            "fireworks": ProviderConfig(
                name="fireworks",
                api_key="your-fireworks-api-key-here",
                model_name="accounts/fireworks/models/deepseek-v3-0324",
                base_url="https://api.fireworks.ai/inference/v1",
                models=[
                    "accounts/fireworks/models/deepseek-v3-0324",
                    "accounts/fireworks/models/llama-v3p1-405b-instruct",
                    "accounts/fireworks/models/llama-v3p1-70b-instruct",
                    "accounts/fireworks/models/llama-v3p1-8b-instruct",
                    "accounts/fireworks/models/mixtral-8x7b-instruct",
                    "accounts/fireworks/models/mixtral-8x22b-instruct"
                ]
            ),
            # OpenAIå…¼å®¹æ¨¡å¼ (Lambda AI) - æ”¯æŒOpenAIå…¼å®¹çš„APIæ¥å£ï¼Œæä¾›å¤šç§å¼€æºæ¨¡å‹
            "lambda": ProviderConfig(
                name="lambda",
                api_key="your-lambda-api-key-here",
                model_name="llama-4-maverick-17b-128e-instruct-fp8",
                base_url="https://api.lambda.ai/v1",
                models=[
                    "llama-4-maverick-17b-128e-instruct-fp8",
                    "llama-4-scout-17b-16e-instruct",
                    "deepseek-r1-0528",
                    "deepseek-v3-0324",
                    "llama3.1-8b-instruct",
                    "llama3.1-70b-instruct-fp8",
                    "llama3.1-405b-instruct-fp8",
                    "llama3.3-70b-instruct-fp8",
                    "qwen3-32b-fp8",
                    "hermes3-8b",
                    "hermes3-70b",
                    "hermes3-405b"
                ]
            )
        }
        
        with self._config_lock:
            self._providers = default_configs
    
    def get_provider_list(self) -> List[str]:
        """è·å–æ‰€æœ‰æ”¯æŒçš„æä¾›å•†åˆ—è¡¨ï¼ˆå†…éƒ¨æ ‡è¯†ç¬¦ï¼‰"""
        with self._config_lock:
            return list(self._providers.keys())
    
    def get_provider_display_name(self, provider_name: str) -> str:
        """è·å–æä¾›å•†æ˜¾ç¤ºåç§°"""
        return PROVIDER_DISPLAY_NAMES.get(provider_name, provider_name.upper())
    
    def get_provider_display_list(self) -> Dict[str, str]:
        """è·å–æä¾›å•†æ˜¾ç¤ºåç§°åˆ—è¡¨ï¼ˆå†…éƒ¨å: æ˜¾ç¤ºåï¼‰"""
        with self._config_lock:
            return {name: self.get_provider_display_name(name) for name in self._providers.keys()}
    
    def get_provider_models(self, provider_name: str, refresh: bool = False) -> List[str]:
        """è·å–æŒ‡å®šæä¾›å•†çš„æ¨¡å‹åˆ—è¡¨"""
        # é¦–å…ˆè·å–åŸºæœ¬ä¿¡æ¯ï¼ˆæ— é”è·å–ï¼Œé¿å…é•¿æ—¶é—´é˜»å¡ï¼‰
        config = None
        try:
            with self._config_lock:
                if provider_name not in self._providers:
                    print(f"âŒ æä¾›å•† {provider_name} ä¸å­˜åœ¨äºé…ç½®ä¸­")
                    return []
                config = self._providers[provider_name]
            
            # æ·±åº¦å®šåˆ¶ï¼šDeepSeek æ¨¡å‹é€‰é¡¹å›ºå®šä¸ºä¸¤ä¸ªï¼Œå¿½ç•¥åˆ·æ–°å’Œè¿œç¨‹åˆ—è¡¨
            if provider_name == "deepseek":
                allowed = ["deepseek-chat", "deepseek-reasoner"]
                # å¦‚æœ‰å¿…è¦ï¼Œæ›´æ–°é…ç½®ä¸­çš„æ¨¡å‹åˆ—è¡¨
                with self._config_lock:
                    if self._providers[provider_name].models != allowed:
                        self._providers[provider_name].models = allowed
                        # å°è¯•å°†æ›´æ”¹æŒä¹…åŒ–
                        try:
                            self.save_config_to_file()
                        except Exception:
                            pass
                print(f"ğŸ“‹ è·å– {provider_name} æ¨¡å‹åˆ—è¡¨ï¼Œå½“å‰æœ‰ {len(allowed)} ä¸ªæ¨¡å‹ï¼Œrefresh={refresh}")
                print("ğŸ”’ DeepSeek æ¨¡å‹é€‰é¡¹å·²å›ºå®šä¸º: deepseek-chat, deepseek-reasoner")
                print(f"ğŸ“¤ è¿”å› {provider_name} æ¨¡å‹åˆ—è¡¨ï¼Œå…± {len(allowed)} ä¸ªæ¨¡å‹")
                return allowed
            
            print(f"ğŸ“‹ è·å– {provider_name} æ¨¡å‹åˆ—è¡¨ï¼Œå½“å‰æœ‰ {len(config.models)} ä¸ªæ¨¡å‹ï¼Œrefresh={refresh}")
            
            # å¦‚æœéœ€è¦åˆ·æ–°æˆ–è€…æ¨¡å‹åˆ—è¡¨ä¸ºç©ºï¼Œå°è¯•ä»APIè·å–
            if refresh or not config.models:
                print(f"ğŸ”„ éœ€è¦åˆ·æ–°æ¨¡å‹åˆ—è¡¨: refresh={refresh}, å½“å‰æ¨¡å‹æ•°é‡={len(config.models)}")
                
                if ModelFetcher:
                    try:
                        print(f"ğŸ”§ ä½¿ç”¨ModelFetcherè·å– {provider_name} çš„æ¨¡å‹åˆ—è¡¨")
                        # åœ¨é”å¤–æ‰§è¡Œç½‘ç»œè¯·æ±‚ï¼Œé¿å…é˜»å¡å…¶ä»–æ“ä½œ
                        fetcher = ModelFetcher()
                        fresh_models = fetcher.fetch_models(
                            provider_name, 
                            config.api_key, 
                            base_url=config.base_url
                        )
                        print(f"ğŸ“¥ ModelFetcherè¿”å› {len(fresh_models)} ä¸ªæ¨¡å‹")
                        
                        if fresh_models:
                            # æå–æ¨¡å‹IDåˆ—è¡¨
                            model_ids = [model.id for model in fresh_models]
                            # åªåœ¨æ›´æ–°é…ç½®æ—¶ä½¿ç”¨é”
                            with self._config_lock:
                                self._providers[provider_name].models = model_ids
                                print(f"ğŸ’¾ æ›´æ–° {provider_name} é…ç½®ä¸­çš„æ¨¡å‹åˆ—è¡¨")
                            # ä¿å­˜æ›´æ–°åçš„é…ç½®
                            self.save_config_to_file()
                            result = model_ids.copy()
                        else:
                            print(f"âš ï¸ ModelFetcherè¿”å›ç©ºåˆ—è¡¨ï¼Œä¿æŒåŸæœ‰æ¨¡å‹åˆ—è¡¨")
                            result = config.models.copy()
                    except Exception as e:
                        import traceback
                        print(f"âŒ åˆ·æ–°{provider_name}æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
                        print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
                        result = config.models.copy()
                else:
                    print("âŒ ModelFetcheræ¨¡å—æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹åˆ—è¡¨")
                    result = config.models.copy()
            else:
                result = config.models.copy()
            
            print(f"ğŸ“¤ è¿”å› {provider_name} æ¨¡å‹åˆ—è¡¨ï¼Œå…± {len(result)} ä¸ªæ¨¡å‹")
            return result
            
        except Exception as e:
            print(f"âŒ è·å–{provider_name}æ¨¡å‹åˆ—è¡¨æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            return []
    
    def refresh_provider_models(self, provider_name: str) -> List[str]:
        """å¼ºåˆ¶åˆ·æ–°æŒ‡å®šæä¾›å•†çš„æ¨¡å‹åˆ—è¡¨"""
        return self.get_provider_models(provider_name, refresh=True)
    
    def get_current_provider(self) -> str:
        """è·å–å½“å‰ä½¿ç”¨çš„æä¾›å•†"""
        with self._config_lock:
            return self._current_provider
    
    def get_provider_config(self, provider_name: str) -> Optional[ProviderConfig]:
        """è·å–æŒ‡å®šæä¾›å•†çš„é…ç½®"""
        with self._config_lock:
            return self._providers.get(provider_name)
    
    def get_current_config(self) -> Optional[ProviderConfig]:
        """è·å–å½“å‰æä¾›å•†çš„é…ç½®"""
        with self._config_lock:
            return self._providers.get(self._current_provider)
    
    def update_provider_config(self, provider_name: str, api_key: str, model_name: str, system_prompt: str = "", base_url: str = None) -> bool:
        """æ›´æ–°æä¾›å•†é…ç½®"""
        with self._config_lock:
            if provider_name not in self._providers:
                return False
            
            config = self._providers[provider_name]
            config.api_key = api_key
            config.model_name = model_name
            config.system_prompt = system_prompt
            if base_url is not None:
                config.base_url = base_url
            return True
    
    def set_current_provider(self, provider_name: str) -> bool:
        """è®¾ç½®å½“å‰ä½¿ç”¨çš„æä¾›å•†"""
        with self._config_lock:
            if provider_name not in self._providers:
                return False
            self._current_provider = provider_name
            return True
    
    def save_config_to_file(self, config_path: str = "runtime_config.json"):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        try:
            config_data = {}
            
            with self._config_lock:
                config_data["current_provider"] = self._current_provider
                config_data["debug_level"] = self._debug_level
                config_data["json_auto_repair"] = self._json_auto_repair
                config_data["cosyvoice_mode"] = self._cosyvoice_mode
                config_data["tts_provider"] = self._tts_provider
                config_data["tts_model"] = self._tts_model
                config_data["tts_api_key"] = self._tts_api_key
                config_data["tts_base_url"] = self._tts_base_url
                config_data["providers"] = {}
                
                for name, provider_config in self._providers.items():
                    config_data["providers"][name] = asdict(provider_config)
            
            # æ–‡ä»¶æ“ä½œåœ¨é”å¤–è¿›è¡Œ
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(config_data, f, ensure_ascii=False, indent=2)
            
            print(f"é…ç½®å·²ä¿å­˜åˆ° {config_path}")
            return True
        except Exception as e:
            print(f"ä¿å­˜é…ç½®å¤±è´¥: {e}")
            return False
    
    def load_config_from_file(self, config_path: str = "runtime_config.json"):
        """ä»æ–‡ä»¶åŠ è½½é…ç½®"""
        if not os.path.exists(config_path):
            print(f"é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return False
        
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config_data = json.load(f)
            
            with self._config_lock:
                self._current_provider = config_data.get("current_provider", "deepseek")
                self._debug_level = config_data.get("debug_level", "1")
                self._json_auto_repair = config_data.get("json_auto_repair", True)
                self._cosyvoice_mode = config_data.get("cosyvoice_mode", False)
                self._tts_provider = config_data.get("tts_provider", "")
                self._tts_model = config_data.get("tts_model", "")
                self._tts_api_key = config_data.get("tts_api_key", "")
                self._tts_base_url = config_data.get("tts_base_url", "")
                
                # ä¸å†è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œç»Ÿä¸€ä»é…ç½®æ–‡ä»¶è¯»å–
                
                # åŠ è½½æä¾›å•†é…ç½®
                for name, provider_data in config_data.get("providers", {}).items():
                    if name in self._providers:
                        # æ›´æ–°ç°æœ‰é…ç½®
                        config = self._providers[name]
                        config.api_key = provider_data.get("api_key", config.api_key)
                        config.model_name = provider_data.get("model_name", config.model_name)
                        config.system_prompt = provider_data.get("system_prompt", config.system_prompt)
                        if "base_url" in provider_data:
                            config.base_url = provider_data["base_url"]
                        if "models" in provider_data:
                            config.models = provider_data["models"]
            
            print(f"é…ç½®å·²ä» {config_path} åŠ è½½")
            return True
        except Exception as e:
            print(f"åŠ è½½é…ç½®å¤±è´¥: {e}")
            return False
    
    def validate_config(self, provider_name: str) -> bool:
        """éªŒè¯é…ç½®æ˜¯å¦æœ‰æ•ˆ"""
        with self._config_lock:
            if provider_name not in self._providers:
                return False
            
            config = self._providers[provider_name]
            
            # å¯¹äºéæœ¬åœ°æä¾›å•†ï¼Œæ£€æŸ¥APIå¯†é’¥
            if provider_name != "lmstudio":
                if not config.api_key or "your-" in config.api_key.lower():
                    return False
            
            return True
    
    def get_chatllm_instance(self):
        """è·å–å½“å‰é…ç½®çš„ChatLLMå®ä¾‹"""
        current_config = self.get_current_config()
        if not current_config:
            raise ValueError("No current provider configured")
        
        if not self.validate_config(self._current_provider):
            raise ValueError(f"Invalid configuration for {self._current_provider}")
        
        # åŠ¨æ€å¯¼å…¥å¯¹åº”çš„ChatLLMå‡½æ•°
        provider_name = self._current_provider
        
        if provider_name == "deepseek":
            from uniai.deepseekAI import deepseekChatLLM
            return deepseekChatLLM(
                model_name=current_config.model_name,
                api_key=current_config.api_key,
                system_prompt=current_config.system_prompt
            )
        elif provider_name == "ali":
            from uniai.aliAI import aliChatLLM
            return aliChatLLM(
                model_name=current_config.model_name,
                api_key=current_config.api_key,
                system_prompt=current_config.system_prompt
            )
        # elif provider_name == "zhipu":
        #     from uniai.zhipuAI import zhipuChatLLM
        #     return zhipuChatLLM(
        #         model_name=current_config.model_name,
        #         api_key=current_config.api_key,
        #         system_prompt=current_config.system_prompt
        #     )
        elif provider_name == "lmstudio":
            from uniai.lmstudioAI import lmstudioChatLLM
            print(f"ğŸ”§ LM Studio é…ç½®çš„ç³»ç»Ÿæç¤ºè¯é•¿åº¦: {len(current_config.system_prompt)} å­—ç¬¦")
            if current_config.system_prompt:
                print(f"ğŸ”§ LM Studio ç³»ç»Ÿæç¤ºè¯å†…å®¹é¢„è§ˆ: {current_config.system_prompt[:100]}...")
            return lmstudioChatLLM(
                model_name=current_config.model_name,
                api_key=current_config.api_key,
                base_url=current_config.base_url,
                system_prompt=current_config.system_prompt
            )
        elif provider_name == "gemini":
            from uniai.geminiAI import geminiChatLLM
            return geminiChatLLM(
                model_name=current_config.model_name,
                api_key=current_config.api_key,
                system_prompt=current_config.system_prompt
            )
        elif provider_name == "openrouter":
            from uniai.openrouterAI import openrouterChatLLM
            return openrouterChatLLM(
                model_name=current_config.model_name,
                api_key=current_config.api_key,
                base_url=current_config.base_url,
                system_prompt=current_config.system_prompt,
                provider_routing=current_config.provider_routing
            )
        elif provider_name == "claude":
            from uniai.claudeAI import claudeChatLLM
            return claudeChatLLM(
                model_name=current_config.model_name,
                api_key=current_config.api_key,
                system_prompt=current_config.system_prompt
            )
        elif provider_name == "grok":
            from uniai.grokAI import grokChatLLM
            return grokChatLLM(
                model_name=current_config.model_name,
                api_key=current_config.api_key,
                base_url=current_config.base_url,
                system_prompt=current_config.system_prompt
            )
        elif provider_name == "fireworks":
            from uniai.fireworksAI import fireworksChatLLM
            return fireworksChatLLM(
                model_name=current_config.model_name,
                api_key=current_config.api_key,
                system_prompt=current_config.system_prompt
            )
        else:
            raise ValueError(f"Unsupported provider: {provider_name}")
    
    def get_debug_level(self) -> str:
        """è·å–å½“å‰è°ƒè¯•çº§åˆ«"""
        with self._config_lock:
            return self._debug_level
    
    def set_debug_level(self, debug_level: str) -> bool:
        """è®¾ç½®è°ƒè¯•çº§åˆ«å¹¶ä¿å­˜åˆ°é…ç½®æ–‡ä»¶"""
        try:
            # éªŒè¯è°ƒè¯•çº§åˆ«
            if debug_level not in ['0', '1', '2']:
                print(f"æ— æ•ˆçš„è°ƒè¯•çº§åˆ«: {debug_level}ï¼Œä½¿ç”¨é»˜è®¤å€¼1")
                debug_level = '1'
            
            with self._config_lock:
                old_level = self._debug_level
                self._debug_level = debug_level
                
                # ä¸å†è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œç»Ÿä¸€ä»é…ç½®æ–‡ä»¶è¯»å–
                
                # åªåœ¨éé™é»˜æ¨¡å¼ä¸‹æ˜¾ç¤ºè°ƒè¯•çº§åˆ«å˜æ›´ä¿¡æ¯
                if debug_level != '0':
                    print(f"è°ƒè¯•çº§åˆ«å·²ä» {old_level} æ›´æ”¹ä¸º {debug_level}")
            
            # ä¿å­˜åˆ°é…ç½®æ–‡ä»¶
            return self.save_config_to_file()
            
        except Exception as e:
            print(f"è®¾ç½®è°ƒè¯•çº§åˆ«å¤±è´¥: {e}")
            return False
    
    def get_json_auto_repair(self) -> bool:
        """è·å–JSONè‡ªåŠ¨ä¿®å¤å¼€å…³çŠ¶æ€"""
        with self._config_lock:
            return self._json_auto_repair
    
    def set_json_auto_repair(self, enabled: bool) -> bool:
        """è®¾ç½®JSONè‡ªåŠ¨ä¿®å¤å¼€å…³å¹¶ä¿å­˜åˆ°é…ç½®æ–‡ä»¶"""
        try:
            with self._config_lock:
                old_state = self._json_auto_repair
                self._json_auto_repair = enabled
                
                print(f"JSONè‡ªåŠ¨ä¿®å¤å·²{'å¼€å¯' if enabled else 'å…³é—­'} (åŸçŠ¶æ€: {'å¼€å¯' if old_state else 'å…³é—­'})")
            
            # ä¿å­˜åˆ°é…ç½®æ–‡ä»¶
            return self.save_config_to_file()
            
        except Exception as e:
            print(f"è®¾ç½®JSONè‡ªåŠ¨ä¿®å¤å¤±è´¥: {e}")
            return False
    
    def get_cosyvoice_mode(self) -> bool:
        """è·å–CosyVoice2æ¨¡å¼çŠ¶æ€"""
        with self._config_lock:
            return self._cosyvoice_mode
    
    def set_cosyvoice_mode(self, enabled: bool) -> bool:
        """è®¾ç½®CosyVoice2æ¨¡å¼å¹¶ä¿å­˜åˆ°é…ç½®æ–‡ä»¶"""
        try:
            with self._config_lock:
                old_state = self._cosyvoice_mode
                self._cosyvoice_mode = enabled
                
                print(f"CosyVoice2æ¨¡å¼å·²{'å¼€å¯' if enabled else 'å…³é—­'} (åŸçŠ¶æ€: {'å¼€å¯' if old_state else 'å…³é—­'})")
            
            # ä¿å­˜åˆ°é…ç½®æ–‡ä»¶
            return self.save_config_to_file()
            
        except Exception as e:
            print(f"è®¾ç½®CosyVoice2æ¨¡å¼å¤±è´¥: {e}")
            return False
    
    def get_tts_provider(self) -> str:
        """è·å–TTSå¤„ç†ä¸“ç”¨æä¾›å•†"""
        with self._config_lock:
            return self._tts_provider
    
    def get_tts_model(self) -> str:
        """è·å–TTSå¤„ç†ä¸“ç”¨æ¨¡å‹"""
        with self._config_lock:
            return self._tts_model
    
    def get_tts_api_key(self) -> str:
        """è·å–TTSå¤„ç†ä¸“ç”¨APIå¯†é’¥"""
        with self._config_lock:
            return getattr(self, '_tts_api_key', '')
    
    def get_tts_base_url(self) -> str:
        """è·å–TTSå¤„ç†ä¸“ç”¨åŸºç¡€URL"""
        with self._config_lock:
            return getattr(self, '_tts_base_url', '')
    
    def set_tts_config(self, provider: str = "", model: str = "", api_key: str = "", base_url: str = "") -> bool:
        """è®¾ç½®TTSå¤„ç†ä¸“ç”¨é…ç½®å¹¶ä¿å­˜åˆ°é…ç½®æ–‡ä»¶"""
        try:
            with self._config_lock:
                old_provider = self._tts_provider
                old_model = self._tts_model
                old_api_key = getattr(self, '_tts_api_key', '')
                old_base_url = getattr(self, '_tts_base_url', '')
                
                self._tts_provider = provider
                self._tts_model = model
                self._tts_api_key = api_key
                self._tts_base_url = base_url
                
                provider_desc = provider if provider else "ä½¿ç”¨å½“å‰æä¾›å•†"
                model_desc = model if model else "ä½¿ç”¨å½“å‰æ¨¡å‹"
                api_key_desc = "å·²è®¾ç½®ç‹¬ç«‹å¯†é’¥" if api_key else "ä½¿ç”¨ä¸»é…ç½®å¯†é’¥"
                base_url_desc = f"ç‹¬ç«‹URL: {base_url}" if base_url else "ä½¿ç”¨ä¸»é…ç½®URL"
                
                print(f"TTSé…ç½®å·²æ›´æ–°:")
                print(f"  æä¾›å•†: {provider_desc}")
                print(f"  æ¨¡å‹: {model_desc}")
                print(f"  APIå¯†é’¥: {api_key_desc}")
                print(f"  åŸºç¡€URL: {base_url_desc}")
                print(f"åŸé…ç½®: æä¾›å•†={old_provider or 'ä½¿ç”¨å½“å‰æä¾›å•†'}, æ¨¡å‹={old_model or 'ä½¿ç”¨å½“å‰æ¨¡å‹'}")
            
            # ä¿å­˜åˆ°é…ç½®æ–‡ä»¶
            return self.save_config_to_file()
            
        except Exception as e:
            print(f"è®¾ç½®TTSé…ç½®å¤±è´¥: {e}")
            return False
    
    def get_effective_tts_config(self):
        """è·å–æœ‰æ•ˆçš„TTSé…ç½®ï¼ˆå¦‚æœTTSä¸“ç”¨é…ç½®ä¸ºç©ºï¼Œåˆ™ä½¿ç”¨å½“å‰é…ç½®ï¼‰"""
        with self._config_lock:
            provider = self._tts_provider if self._tts_provider else self._current_provider
            
            # è·å–æœ‰æ•ˆæ¨¡å‹
            if self._tts_model:
                model = self._tts_model
            else:
                # ä½¿ç”¨å½“å‰é…ç½®çš„æ¨¡å‹
                current_config = self.get_current_config()
                model = current_config.model_name if current_config else ""
            
            return provider, model

# å…¨å±€é…ç½®ç®¡ç†å™¨å®ä¾‹
_config_manager = None
_config_lock = threading.Lock()

def get_config_manager() -> DynamicConfigManager:
    """è·å–å…¨å±€é…ç½®ç®¡ç†å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _config_manager
    if _config_manager is None:
        with _config_lock:
            if _config_manager is None:  # åŒé‡æ£€æŸ¥
                _config_manager = DynamicConfigManager()
    return _config_manager

# å…¼å®¹æ€§å‡½æ•°
def get_dynamic_chatllm():
    """è·å–åŠ¨æ€é…ç½®çš„ChatLLMå®ä¾‹"""
    return _config_manager.get_chatllm_instance()

if __name__ == "__main__":
    # æµ‹è¯•é…ç½®ç®¡ç†å™¨
    manager = get_config_manager()
    print("æ”¯æŒçš„æä¾›å•†:", manager.get_provider_list())
    print("å½“å‰æä¾›å•†:", manager.get_current_provider())
    print("å½“å‰é…ç½®:", manager.get_current_config())