#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Tokenç›‘æ§å·¥å…· - ç”¨äºåˆ†æå’Œä¼˜åŒ–Tokenæ¶ˆè€—
"""

class TokenMonitor:
    """Tokenæ¶ˆè€—ç›‘æ§å™¨"""
    
    def __init__(self):
        self.stats = {
            'writer': {'count': 0, 'total_tokens': 0, 'input_tokens': 0, 'output_tokens': 0},
            'embellisher': {'count': 0, 'total_tokens': 0, 'input_tokens': 0, 'output_tokens': 0},
            'memory': {'count': 0, 'total_tokens': 0, 'input_tokens': 0, 'output_tokens': 0},
            'other': {'count': 0, 'total_tokens': 0, 'input_tokens': 0, 'output_tokens': 0},
        }
        self.input_breakdown = {}  # è¯¦ç»†çš„è¾“å…¥å‚æ•°ç»Ÿè®¡
    
    def estimate_tokens(self, text):
        """
        ä¼°ç®—æ–‡æœ¬çš„tokenæ•°é‡
        ä¸­æ–‡ï¼šçº¦1.5å­—ç¬¦/token
        è‹±æ–‡ï¼šçº¦4å­—ç¬¦/token
        """
        if not text:
            return 0
        
        # ç®€å•ä¼°ç®—ï¼šä¸­æ–‡ä¸ºä¸»çš„æ–‡æœ¬
        chinese_chars = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
        other_chars = len(text) - chinese_chars
        
        # ä¸­æ–‡çº¦1.5å­—ç¬¦/tokenï¼Œè‹±æ–‡çº¦4å­—ç¬¦/token
        estimated_tokens = int(chinese_chars / 1.5 + other_chars / 4)
        return estimated_tokens
    
    def record_writer_call(self, inputs, output):
        """è®°å½•æ­£æ–‡ç”Ÿæˆè°ƒç”¨"""
        input_tokens = sum(self.estimate_tokens(str(v)) for v in inputs.values())
        output_tokens = self.estimate_tokens(str(output))
        
        self.stats['writer']['count'] += 1
        self.stats['writer']['input_tokens'] += input_tokens
        self.stats['writer']['output_tokens'] += output_tokens
        self.stats['writer']['total_tokens'] += input_tokens + output_tokens
        
        # è®°å½•è¾“å…¥å‚æ•°è¯¦æƒ…
        for key, value in inputs.items():
            if key not in self.input_breakdown:
                self.input_breakdown[key] = {'count': 0, 'total_tokens': 0}
            
            tokens = self.estimate_tokens(str(value))
            self.input_breakdown[key]['count'] += 1
            self.input_breakdown[key]['total_tokens'] += tokens
    
    def record_embellisher_call(self, inputs, output):
        """è®°å½•æ¶¦è‰²è°ƒç”¨"""
        input_tokens = sum(self.estimate_tokens(str(v)) for v in inputs.values())
        output_tokens = self.estimate_tokens(str(output))
        
        self.stats['embellisher']['count'] += 1
        self.stats['embellisher']['input_tokens'] += input_tokens
        self.stats['embellisher']['output_tokens'] += output_tokens
        self.stats['embellisher']['total_tokens'] += input_tokens + output_tokens
    
    def record_memory_call(self, inputs, output):
        """è®°å½•è®°å¿†ç”Ÿæˆè°ƒç”¨"""
        input_tokens = sum(self.estimate_tokens(str(v)) for v in inputs.values())
        output_tokens = self.estimate_tokens(str(output))
        
        self.stats['memory']['count'] += 1
        self.stats['memory']['input_tokens'] += input_tokens
        self.stats['memory']['output_tokens'] += output_tokens
        self.stats['memory']['total_tokens'] += input_tokens + output_tokens
    
    def get_report(self):
        """ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š"""
        total_tokens = sum(s['total_tokens'] for s in self.stats.values())
        total_calls = sum(s['count'] for s in self.stats.values())
        
        report = []
        report.append("=" * 60)
        report.append("ğŸ“Š Tokenæ¶ˆè€—ç»Ÿè®¡æŠ¥å‘Š")
        report.append("=" * 60)
        
        # æ€»ä½“ç»Ÿè®¡
        report.append(f"\næ€»è°ƒç”¨æ¬¡æ•°: {total_calls}")
        report.append(f"æ€»Tokenæ¶ˆè€—: {total_tokens:,}")
        report.append(f"å¹³å‡æ¯æ¬¡è°ƒç”¨: {total_tokens // total_calls if total_calls > 0 else 0:,} tokens")
        
        # åˆ†ç±»ç»Ÿè®¡
        report.append("\n" + "-" * 60)
        report.append("åˆ†ç±»ç»Ÿè®¡:")
        report.append("-" * 60)
        
        for category, data in self.stats.items():
            if data['count'] > 0:
                percentage = (data['total_tokens'] / total_tokens * 100) if total_tokens > 0 else 0
                report.append(f"\n{category.upper()}:")
                report.append(f"  è°ƒç”¨æ¬¡æ•°: {data['count']}")
                report.append(f"  è¾“å…¥Token: {data['input_tokens']:,}")
                report.append(f"  è¾“å‡ºToken: {data['output_tokens']:,}")
                report.append(f"  æ€»è®¡: {data['total_tokens']:,} ({percentage:.1f}%)")
                report.append(f"  å¹³å‡æ¯æ¬¡: {data['total_tokens'] // data['count']:,} tokens")
        
        # è¾“å…¥å‚æ•°è¯¦ç»†ç»Ÿè®¡ï¼ˆä»…æ­£æ–‡ç”Ÿæˆï¼‰
        if self.input_breakdown:
            report.append("\n" + "-" * 60)
            report.append("æ­£æ–‡ç”Ÿæˆè¾“å…¥å‚æ•°è¯¦ç»†ç»Ÿè®¡:")
            report.append("-" * 60)
            
            # æŒ‰tokenæ¶ˆè€—æ’åº
            sorted_params = sorted(
                self.input_breakdown.items(),
                key=lambda x: x[1]['total_tokens'],
                reverse=True
            )
            
            for param, data in sorted_params:
                if data['total_tokens'] > 0:
                    avg_tokens = data['total_tokens'] // data['count'] if data['count'] > 0 else 0
                    report.append(f"\n  {param}:")
                    report.append(f"    ä½¿ç”¨æ¬¡æ•°: {data['count']}")
                    report.append(f"    æ€»Token: {data['total_tokens']:,}")
                    report.append(f"    å¹³å‡: {avg_tokens:,} tokens/æ¬¡")
        
        # ä¼˜åŒ–å»ºè®®
        report.append("\n" + "=" * 60)
        report.append("ğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        report.append("=" * 60)
        
        suggestions = self._generate_suggestions()
        for i, suggestion in enumerate(suggestions, 1):
            report.append(f"{i}. {suggestion}")
        
        report.append("=" * 60)
        
        return '\n'.join(report)
    
    def _generate_suggestions(self):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = []
        
        # åˆ†ææ­£æ–‡ç”Ÿæˆçš„è¾“å…¥å‚æ•°
        if self.input_breakdown:
            sorted_params = sorted(
                self.input_breakdown.items(),
                key=lambda x: x[1]['total_tokens'],
                reverse=True
            )
            
            # æ‰¾å‡ºæ¶ˆè€—æœ€å¤§çš„å‚æ•°
            top_params = sorted_params[:3]
            for param, data in top_params:
                avg = data['total_tokens'] // data['count'] if data['count'] > 0 else 0
                if avg > 500:  # å¦‚æœå¹³å‡è¶…è¿‡500 tokens
                    if param == 'å¤§çº²':
                        suggestions.append(f"'{param}'å¹³å‡æ¶ˆè€—{avg}tokensï¼Œå»ºè®®ä½¿ç”¨å¤§çº²ä¼˜åŒ–å™¨æå–ç›¸å…³ç‰‡æ®µ")
                    elif param == 'å‰æ–‡è®°å¿†':
                        suggestions.append(f"'{param}'å¹³å‡æ¶ˆè€—{avg}tokensï¼Œå»ºè®®é™ä½è®°å¿†é•¿åº¦é™åˆ¶")
                    elif param in ['å‰äº”ç« æ€»ç»“', 'åäº”ç« æ¢—æ¦‚']:
                        suggestions.append(f"'{param}'å¹³å‡æ¶ˆè€—{avg}tokensï¼Œå»ºè®®å‡å°‘åˆ°å‰å2-3ç« ")
                    elif param == 'äººç‰©åˆ—è¡¨':
                        suggestions.append(f"'{param}'å¹³å‡æ¶ˆè€—{avg}tokensï¼Œå»ºè®®åªå‘é€ç›¸å…³è§’è‰²ä¿¡æ¯")
                    else:
                        suggestions.append(f"'{param}'å¹³å‡æ¶ˆè€—{avg}tokensï¼Œå»ºè®®è¿›è¡Œå‹ç¼©æˆ–ç²¾ç®€")
        
        # åˆ†ææ­£æ–‡ç”Ÿæˆvsæ¶¦è‰²çš„æ¯”ä¾‹
        writer_tokens = self.stats['writer']['total_tokens']
        embellisher_tokens = self.stats['embellisher']['total_tokens']
        
        if writer_tokens > 0 and embellisher_tokens > 0:
            ratio = writer_tokens / (writer_tokens + embellisher_tokens)
            if ratio > 0.6:
                suggestions.append(f"æ­£æ–‡ç”Ÿæˆå æ¯”{ratio*100:.1f}%ï¼Œå»ºè®®ä¼˜å…ˆä¼˜åŒ–æ­£æ–‡ç”Ÿæˆé˜¶æ®µ")
        
        # å¦‚æœæ²¡æœ‰å…·ä½“å»ºè®®ï¼Œç»™å‡ºé€šç”¨å»ºè®®
        if not suggestions:
            suggestions.append("å½“å‰Tokenæ¶ˆè€—åœ¨åˆç†èŒƒå›´å†…")
            suggestions.append("å¯ä»¥è€ƒè™‘å¯ç”¨ç²¾ç®€æ¨¡å¼å’Œé•¿ç« èŠ‚æ¨¡å¼è¿›ä¸€æ­¥ä¼˜åŒ–")
        
        return suggestions
    
    def save_report(self, filename='token_report.txt'):
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        report = self.get_report()
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"ğŸ“„ Tokenç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")


# å…¨å±€ç›‘æ§å™¨å®ä¾‹
_global_monitor = None

def get_token_monitor():
    """è·å–å…¨å±€Tokenç›‘æ§å™¨"""
    global _global_monitor
    if _global_monitor is None:
        _global_monitor = TokenMonitor()
    return _global_monitor


# å¯¼å‡º
__all__ = ['TokenMonitor', 'get_token_monitor']
