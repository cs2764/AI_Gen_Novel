#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
é…ç½®ç®¡ç†å™¨
è´Ÿè´£åŠ è½½å’Œç®¡ç†AIå°è¯´ç”Ÿæˆå™¨çš„é…ç½®ä¿¡æ¯
"""

import os
import sys
from typing import Dict, Any, Optional

def load_config(allow_incomplete: bool = True) -> Dict[str, Any]:
    """
    åŠ è½½é…ç½®æ–‡ä»¶

    Args:
        allow_incomplete: æ˜¯å¦å…è®¸ä¸å®Œæ•´çš„é…ç½®ï¼ˆç”¨äºWebç•Œé¢å¯åŠ¨ï¼‰

    Returns:
        Dict[str, Any]: é…ç½®å­—å…¸

    Raises:
        SystemExit: å½“é…ç½®æ–‡ä»¶ä¸å­˜åœ¨æˆ–é…ç½®é”™è¯¯æ—¶ï¼ˆé™¤éallow_incomplete=Trueï¼‰
    """
    config_path = "config.py"
    template_path = "config_template.py"

    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(config_path):
        if allow_incomplete:
            print("âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»ºé»˜è®¤é…ç½®...")
            # è‡ªåŠ¨åˆ›å»ºé…ç½®æ–‡ä»¶
            if os.path.exists(template_path):
                import shutil
                shutil.copy2(template_path, config_path)
                print(f"âœ… å·²ä» {template_path} åˆ›å»º {config_path}")
            else:
                # å¦‚æœæ¨¡æ¿æ–‡ä»¶ä¹Ÿä¸å­˜åœ¨ï¼Œåˆ›å»ºæœ€å°é…ç½®
                minimal_config = '''# AIå°è¯´ç”Ÿæˆå™¨ - åŸºç¡€é…ç½®æ–‡ä»¶
CURRENT_PROVIDER = "deepseek"

DEEPSEEK_CONFIG = {
    "api_key": "your-deepseek-api-key-here",
    "model_name": "deepseek-chat",
    "base_url": "https://api.deepseek.com",
    "system_prompt": ""
}

ALI_CONFIG = {
    "api_key": "your-ali-api-key-here",
    "model_name": "qwen-long",
    "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
    "system_prompt": ""
}

LMSTUDIO_CONFIG = {
    "api_key": "not-needed",
    "model_name": "your-local-model-name",
    "base_url": "http://localhost:1234/v1",
    "system_prompt": ""
}

GEMINI_CONFIG = {
    "api_key": "your-gemini-api-key-here",
    "model_name": "gemini-1.5-pro",
    "base_url": "",
    "system_prompt": ""
}

OPENROUTER_CONFIG = {
    "api_key": "your-openrouter-api-key-here",
    "model_name": "anthropic/claude-3.5-sonnet",
    "base_url": "https://openrouter.ai/api/v1",
    "system_prompt": ""
}

CLAUDE_CONFIG = {
    "api_key": "your-claude-api-key-here",
    "model_name": "claude-3-5-sonnet-20241022",
    "base_url": "https://api.anthropic.com",
    "system_prompt": ""
}

GROK_CONFIG = {
    "api_key": "your-grok-api-key-here",
    "model_name": "grok-beta",
    "base_url": "https://api.x.ai/v1",
    "system_prompt": ""
}

LAMBDA_CONFIG = {
    "api_key": "your-lambda-api-key-here",
    "model_name": "llama-4-maverick-17b-128e-instruct-fp8",
    "base_url": "https://api.lambda.ai/v1",
    "system_prompt": ""
}

NOVEL_SETTINGS = {
    "default_chapters": 20,
    "enable_chapters": True,
    "enable_ending": True,
    "auto_save": True,
    "output_dir": "output"
}

TEMPERATURE_SETTINGS = {
    "outline_writer": 0.98,
    "beginning_writer": 0.80,
    "novel_writer": 0.81,
    "embellisher": 0.92,
    "memory_maker": 0.66,
    "title_generator": 0.8,
    "ending_writer": 0.85
}

NETWORK_SETTINGS = {
    "timeout": 300,
    "max_retries": 3,
    "retry_delay": 2.0
}
'''
                with open(config_path, 'w', encoding='utf-8') as f:
                    f.write(minimal_config)
                print(f"âœ… å·²åˆ›å»ºåŸºç¡€ {config_path}")

            print("âš ï¸  é…ç½®æ–‡ä»¶å·²åˆ›å»ºï¼Œä½†éœ€è¦è®¾ç½®APIå¯†é’¥æ‰èƒ½æ­£å¸¸ä½¿ç”¨")
            print("ğŸ’¡ ç¨‹åºå°†å¯åŠ¨ï¼Œè¯·åœ¨Webç•Œé¢çš„è®¾ç½®é¡µé¢ä¸­é…ç½®APIå¯†é’¥")

            return {
                'provider': 'deepseek',
                'config': {'api_key': '', 'model_name': 'deepseek-chat'},
                'novel_settings': {},
                'temperature_settings': {},
                'network_settings': {},
                'all_configs': {},
                'incomplete': True
            }
        else:
            print("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼")
            print(f"ğŸ“‹ è¯·å¤åˆ¶ {template_path} ä¸º {config_path} å¹¶å¡«å…¥æ‚¨çš„é…ç½®ä¿¡æ¯")
            print("\nå¿«é€Ÿè®¾ç½®æ­¥éª¤:")
            print(f"1. å¤åˆ¶æ–‡ä»¶: cp {template_path} {config_path}")
            print(f"2. ç¼–è¾‘æ–‡ä»¶: å¡«å…¥æ‚¨çš„APIå¯†é’¥å’Œè®¾ç½®")
            print(f"3. é‡æ–°è¿è¡Œç¨‹åº")
            sys.exit(1)
    
    # åŠ¨æ€å¯¼å…¥é…ç½®æ¨¡å—
    try:
        import importlib.util
        spec = importlib.util.spec_from_file_location("config", config_path)
        config_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(config_module)
        
        # éªŒè¯å¿…è¦çš„é…ç½®é¡¹
        required_configs = [
            'CURRENT_PROVIDER',
            'DEEPSEEK_CONFIG',
            'ALI_CONFIG', 
            # 'ZHIPU_CONFIG',
            'LMSTUDIO_CONFIG',
            'GEMINI_CONFIG',
            'OPENROUTER_CONFIG',
            'CLAUDE_CONFIG',
            'GROK_CONFIG',
            'LAMBDA_CONFIG'
        ]
        
        for config_name in required_configs:
            if not hasattr(config_module, config_name):
                if allow_incomplete:
                    print(f"âš ï¸  é…ç½®æ–‡ä»¶ç¼ºå°‘é…ç½®é¡¹: {config_name}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                    setattr(config_module, config_name, {})
                else:
                    print(f"âŒ é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…è¦é…ç½®é¡¹: {config_name}")
                    print(f"ğŸ“‹ è¯·å‚è€ƒ {template_path} è¡¥å……é…ç½®")
                    sys.exit(1)
        
        # éªŒè¯å½“å‰æä¾›å•†è®¾ç½®
        provider = config_module.CURRENT_PROVIDER
        valid_providers = ["deepseek", "ali", "lmstudio", "gemini", "openrouter", "claude", "grok", "fireworks", "lambda"]
        
        if provider not in valid_providers:
            if allow_incomplete:
                print(f"âš ï¸  æ— æ•ˆçš„AIæä¾›å•†: {provider}ï¼Œä½¿ç”¨é»˜è®¤å€¼: deepseek")
                provider = "deepseek"
                config_module.CURRENT_PROVIDER = provider
            else:
                print(f"âŒ æ— æ•ˆçš„AIæä¾›å•†: {provider}")
                print(f"ğŸ“‹ è¯·é€‰æ‹©: {', '.join(valid_providers)}")
                sys.exit(1)
            
        # éªŒè¯å¯¹åº”æä¾›å•†çš„APIå¯†é’¥
        provider_configs = {
            "deepseek": config_module.DEEPSEEK_CONFIG,
            "ali": config_module.ALI_CONFIG,
            # "zhipu": config_module.ZHIPU_CONFIG,
            "lmstudio": config_module.LMSTUDIO_CONFIG,
            "gemini": config_module.GEMINI_CONFIG,
            "openrouter": config_module.OPENROUTER_CONFIG,
            "claude": config_module.CLAUDE_CONFIG,
            "grok": config_module.GROK_CONFIG,
            "lambda": config_module.LAMBDA_CONFIG
        }
        
        current_config = provider_configs[provider]
        api_key = current_config.get("api_key", "")
        
        if provider != "lmstudio" and (not api_key or "your-" in api_key.lower()):
            if allow_incomplete:
                print(f"âš ï¸  {provider.upper()}_CONFIG çš„ api_key æœªè®¾ç½®ï¼Œå°†åœ¨Webç•Œé¢ä¸­é…ç½®")
            else:
                print(f"âŒ è¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½® {provider.upper()}_CONFIG çš„ api_key")
                print(f"ğŸ“‹ ç¼–è¾‘ {config_path} æ–‡ä»¶ï¼Œå¡«å…¥æ‚¨çš„APIå¯†é’¥")
                sys.exit(1)
        
        if not allow_incomplete or (provider == "lmstudio" or (api_key and "your-" not in api_key.lower())):
            print(f"âœ… é…ç½®åŠ è½½æˆåŠŸï¼Œå½“å‰ä½¿ç”¨: {provider.upper()}")
        
        return {
            'provider': provider,
            'config': current_config,
            'novel_settings': getattr(config_module, 'NOVEL_SETTINGS', {}),
            'temperature_settings': getattr(config_module, 'TEMPERATURE_SETTINGS', {}),
            'network_settings': getattr(config_module, 'NETWORK_SETTINGS', {}),
            'all_configs': provider_configs,
            'incomplete': allow_incomplete and (provider != "lmstudio" and (not api_key or "your-" in api_key.lower()))
        }
        
    except Exception as e:
        if allow_incomplete:
            print(f"âš ï¸  é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}ï¼Œè¿”å›é»˜è®¤é…ç½®")
            return {
                'provider': 'deepseek',
                'config': {'api_key': '', 'model_name': 'deepseek-chat'},
                'novel_settings': {},
                'temperature_settings': {},
                'network_settings': {},
                'all_configs': {},
                'incomplete': True
            }
        else:
            print(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            print(f"ğŸ“‹ è¯·æ£€æŸ¥ {config_path} æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®")
            print(f"ğŸ’¡ å¯ä»¥åˆ é™¤ {config_path} å¹¶é‡æ–°å¤åˆ¶ {template_path}")
            sys.exit(1)


def get_chatllm(allow_incomplete: bool = True):
    """
    æ ¹æ®é…ç½®è·å–ChatLLMå®ä¾‹ï¼ˆä¼˜å…ˆä½¿ç”¨åŠ¨æ€é…ç½®ï¼‰
    
    Args:
        allow_incomplete: æ˜¯å¦å…è®¸ä¸å®Œæ•´çš„é…ç½®
    
    Returns:
        Callable: ChatLLMå‡½æ•°
    """
    # Try to import AI modules
    try:
        from uniai import (
            aliChatLLM, deepseekChatLLM, lmstudioChatLLM,
            geminiChatLLM, openrouterChatLLM, claudeChatLLM
        )
    except ImportError as import_err:
        if allow_incomplete:
            print(f"âš ï¸  AIæ¨¡å—å¯¼å…¥å¤±è´¥: {import_err}ï¼Œè¿”å›è™šæ‹Ÿå‡½æ•°")
            def dummy_chatllm(*args, **kwargs):
                yield {"content": "AIæ¨¡å—æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…ä¾èµ–: pip install -r requirements.txt", "total_tokens": 0}
            return dummy_chatllm
        else:
            raise
    
    # ä¼˜å…ˆä½¿ç”¨åŠ¨æ€é…ç½®
    try:
        from dynamic_config_manager import get_config_manager
        config_manager = get_config_manager()
        
        provider = config_manager.get_current_provider()
        current_config = config_manager.get_current_config()
        
        # æ£€æŸ¥åŠ¨æ€é…ç½®æ˜¯å¦æœ‰æ•ˆ
        if current_config and current_config.api_key:
            # LM Studioä¸éœ€è¦çœŸå®APIå¯†é’¥
            if provider == "lmstudio" or "your-" not in current_config.api_key.lower():
                print(f"âœ… ä½¿ç”¨åŠ¨æ€é…ç½®ï¼Œå½“å‰æä¾›å•†: {provider.upper()}")
                provider_config = {
                    'api_key': current_config.api_key,
                    'model_name': current_config.model_name,
                    'base_url': current_config.base_url,
                    'system_prompt': current_config.system_prompt
                }
            else:
                # åŠ¨æ€é…ç½®æ— æ•ˆï¼Œå›é€€åˆ°é™æ€é…ç½®
                config = load_config(allow_incomplete=allow_incomplete)
                provider = config['provider']
                provider_config = config['config']

                # å¦‚æœé™æ€é…ç½®ä¹Ÿæ— æ•ˆä¸”å…è®¸ä¸å®Œæ•´é…ç½®ï¼Œè¿”å›æç¤ºå‡½æ•°
                if allow_incomplete and config.get('incomplete', False):
                    def incomplete_config_chatllm(*args, **kwargs):
                        yield {
                            "content": "âš ï¸ APIå¯†é’¥æœªé…ç½®ï¼Œè¯·åœ¨è®¾ç½®é¡µé¢ä¸­é…ç½®æ‚¨çš„APIå¯†é’¥åé‡è¯•ã€‚\n\nå¦‚éœ€å¸®åŠ©ï¼Œè¯·å‚è€ƒé…ç½®è¯´æ˜ã€‚",
                            "total_tokens": 0
                        }
                    return incomplete_config_chatllm
                
                # å¦‚æœé™æ€é…ç½®ä¹Ÿä¸å®Œæ•´ï¼Œè¿”å›å‹å¥½æç¤ºå‡½æ•°
                if config.get('incomplete', False):
                    if allow_incomplete:
                        def incomplete_config_chatllm(*args, **kwargs):
                            yield {
                                "content": "âš ï¸ APIå¯†é’¥æœªé…ç½®ï¼Œè¯·åœ¨è®¾ç½®é¡µé¢ä¸­é…ç½®æ‚¨çš„APIå¯†é’¥åé‡è¯•ã€‚\n\nå¦‚éœ€å¸®åŠ©ï¼Œè¯·å‚è€ƒé…ç½®è¯´æ˜ã€‚",
                                "total_tokens": 0
                            }
                        return incomplete_config_chatllm
                    else:
                        def dummy_chatllm(*args, **kwargs):
                            yield {"content": "è¯·å…ˆåœ¨é…ç½®ç•Œé¢è®¾ç½®APIå¯†é’¥", "total_tokens": 0}
                        return dummy_chatllm
        else:
            # æ²¡æœ‰åŠ¨æ€é…ç½®ï¼Œä½¿ç”¨é™æ€é…ç½®
            config = load_config(allow_incomplete=allow_incomplete)
            provider = config['provider']
            provider_config = config['config']

            # å¦‚æœé™æ€é…ç½®ä¸å®Œæ•´ä¸”å…è®¸ä¸å®Œæ•´é…ç½®ï¼Œè¿”å›å‹å¥½æç¤ºå‡½æ•°
            if config.get('incomplete', False):
                if allow_incomplete:
                    def incomplete_config_chatllm(*args, **kwargs):
                        yield {
                            "content": "âš ï¸ APIå¯†é’¥æœªé…ç½®ï¼Œè¯·åœ¨è®¾ç½®é¡µé¢ä¸­é…ç½®æ‚¨çš„APIå¯†é’¥åé‡è¯•ã€‚\n\nå¦‚éœ€å¸®åŠ©ï¼Œè¯·å‚è€ƒé…ç½®è¯´æ˜ã€‚",
                            "total_tokens": 0
                        }
                    return incomplete_config_chatllm
                else:
                    def dummy_chatllm(*args, **kwargs):
                        yield {"content": "è¯·å…ˆåœ¨é…ç½®ç•Œé¢è®¾ç½®APIå¯†é’¥", "total_tokens": 0}
                    return dummy_chatllm

    except Exception as e:
        print(f"âš ï¸  åŠ¨æ€é…ç½®åŠ è½½å¤±è´¥: {e}ï¼Œå›é€€åˆ°é™æ€é…ç½®")
        config = load_config(allow_incomplete=allow_incomplete)
        provider = config['provider']
        provider_config = config['config']

        # å¦‚æœé™æ€é…ç½®ä¸å®Œæ•´ä¸”å…è®¸ä¸å®Œæ•´é…ç½®ï¼Œè¿”å›å‹å¥½æç¤ºå‡½æ•°
        if config.get('incomplete', False):
            if allow_incomplete:
                def incomplete_config_chatllm(*args, **kwargs):
                    yield {
                        "content": "âš ï¸ APIå¯†é’¥æœªé…ç½®ï¼Œè¯·åœ¨è®¾ç½®é¡µé¢ä¸­é…ç½®æ‚¨çš„APIå¯†é’¥åé‡è¯•ã€‚\n\nå¦‚éœ€å¸®åŠ©ï¼Œè¯·å‚è€ƒé…ç½®è¯´æ˜ã€‚",
                        "total_tokens": 0
                    }
                return incomplete_config_chatllm
            else:
                def dummy_chatllm(*args, **kwargs):
                    yield {"content": "è¯·å…ˆåœ¨é…ç½®ç•Œé¢è®¾ç½®APIå¯†é’¥", "total_tokens": 0}
                return dummy_chatllm
    
    try:
        if provider == "deepseek":
            return deepseekChatLLM(
                model_name=provider_config['model_name'],
                api_key=provider_config['api_key'],
                system_prompt=provider_config.get('system_prompt', '')
            )
        elif provider == "ali":
            return aliChatLLM(
                model_name=provider_config['model_name'],
                api_key=provider_config['api_key'],
                system_prompt=provider_config.get('system_prompt', '')
            )
        # elif provider == "zhipu":
        #     return zhipuChatLLM(
        #         model_name=provider_config['model_name'],
        #         api_key=provider_config['api_key'],
        #         system_prompt=provider_config.get('system_prompt', '')
        #     )
        elif provider == "lmstudio":
            return lmstudioChatLLM(
                model_name=provider_config['model_name'],
                api_key=provider_config['api_key'],
                base_url=provider_config['base_url'],
                system_prompt=provider_config.get('system_prompt', '')
            )
        elif provider == "gemini":
            return geminiChatLLM(
                model_name=provider_config['model_name'],
                api_key=provider_config['api_key'],
                system_prompt=provider_config.get('system_prompt', '')
            )
        elif provider == "openrouter":
            return openrouterChatLLM(
                model_name=provider_config['model_name'],
                api_key=provider_config['api_key'],
                base_url=provider_config.get('base_url'),
                system_prompt=provider_config.get('system_prompt', ''),
                provider_routing=provider_config.get('provider_routing')
            )
        elif provider == "claude":
            return claudeChatLLM(
                model_name=provider_config['model_name'],
                api_key=provider_config['api_key'],
                system_prompt=provider_config.get('system_prompt', '')
            )
        elif provider == "grok":
            from uniai.grokAI import grokChatLLM
            return grokChatLLM(
                model_name=provider_config['model_name'],
                api_key=provider_config['api_key'],
                base_url=provider_config.get('base_url'),
                system_prompt=provider_config.get('system_prompt', '')
            )
        elif provider == "fireworks":
            from uniai.fireworksAI import fireworksChatLLM
            return fireworksChatLLM(
                model_name=provider_config['model_name'],
                api_key=provider_config['api_key'],
                system_prompt=provider_config.get('system_prompt', '')
            )
        elif provider == "lambda":
            from uniai.lambdaAI import lambdaChatLLM
            return lambdaChatLLM(
                model_name=provider_config['model_name'],
                api_key=provider_config['api_key'],
                base_url=provider_config.get('base_url'),
                system_prompt=provider_config.get('system_prompt', '')
            )
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„AIæä¾›å•†: {provider}")
            
    except Exception as e:
        if allow_incomplete:
            print(f"âš ï¸  åˆå§‹åŒ–AIæä¾›å•†å¤±è´¥: {e}ï¼Œè¿”å›è™šæ‹Ÿå‡½æ•°")
            def dummy_chatllm(*args, **kwargs):
                yield {"content": f"AIæä¾›å•†åˆå§‹åŒ–å¤±è´¥: {e}", "total_tokens": 0}
            return dummy_chatllm
        else:
            print(f"âŒ åˆå§‹åŒ–AIæä¾›å•†å¤±è´¥: {e}")
            print(f"ğŸ“‹ è¯·æ£€æŸ¥ {provider.upper()}_CONFIG é…ç½®æ˜¯å¦æ­£ç¡®")
            sys.exit(1)


def update_aign_settings(aign_instance, allow_incomplete: bool = True):
    """
    æ ¹æ®é…ç½®æ›´æ–°AIGNå®ä¾‹çš„è®¾ç½®
    
    Args:
        aign_instance: AIGNå®ä¾‹
        allow_incomplete: æ˜¯å¦å…è®¸ä¸å®Œæ•´çš„é…ç½®
    """
    config = load_config(allow_incomplete=allow_incomplete)
    
    # åº”ç”¨å°è¯´è®¾ç½®
    novel_settings = config.get('novel_settings', {})
    if novel_settings:
        aign_instance.target_chapter_count = novel_settings.get('default_chapters', 20)
        aign_instance.enable_chapters = novel_settings.get('enable_chapters', True)
        aign_instance.enable_ending = novel_settings.get('enable_ending', True)
    
    # åº”ç”¨æ¸©åº¦è®¾ç½®
    temp_settings = config.get('temperature_settings', {})
    if temp_settings:
        aign_instance.novel_outline_writer.temperature = temp_settings.get('outline_writer', 0.98)
        aign_instance.novel_beginning_writer.temperature = temp_settings.get('beginning_writer', 0.80)
        aign_instance.novel_writer.temperature = temp_settings.get('novel_writer', 0.81)
        aign_instance.novel_embellisher.temperature = temp_settings.get('embellisher', 0.92)
        aign_instance.memory_maker.temperature = temp_settings.get('memory_maker', 0.66)
        aign_instance.title_generator.temperature = temp_settings.get('title_generator', 0.8)
        aign_instance.ending_writer.temperature = temp_settings.get('ending_writer', 0.85)


def print_config_info(allow_incomplete: bool = True):
    """æ‰“å°é…ç½®ä¿¡æ¯ï¼ˆä¸åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼‰"""
    try:
        config = load_config(allow_incomplete=allow_incomplete)
        provider = config['provider']
        provider_config = config['config']

        print("=" * 50)
        print("ğŸ”§ å½“å‰é…ç½®ä¿¡æ¯")
        print("=" * 50)
        print(f"ğŸ“¡ AIæä¾›å•†: {provider.upper()}")
        print(f"ğŸ¤– æ¨¡å‹åç§°: {provider_config.get('model_name', 'æœªè®¾ç½®')}")

        api_key = provider_config.get('api_key', '')
        if api_key:
            print(f"ğŸ”‘ APIå¯†é’¥: {'*' * (len(api_key) - 4)}{api_key[-4:] if len(api_key) > 4 else '****'}")
        else:
            print(f"ğŸ”‘ APIå¯†é’¥: æœªè®¾ç½®")

        if provider_config.get('base_url'):
            print(f"ğŸŒ APIåœ°å€: {provider_config['base_url']}")

        novel_settings = config.get('novel_settings', {})
        if novel_settings:
            print(f"ğŸ“š é»˜è®¤ç« èŠ‚æ•°: {novel_settings.get('default_chapters', 20)}")
            print(f"ğŸ“– ç« èŠ‚æ ‡é¢˜: {'å¯ç”¨' if novel_settings.get('enable_chapters', True) else 'ç¦ç”¨'}")
            print(f"ğŸ¯ æ™ºèƒ½ç»“å°¾: {'å¯ç”¨' if novel_settings.get('enable_ending', True) else 'ç¦ç”¨'}")

        if config.get('incomplete', False):
            print("âš ï¸  é…ç½®ä¸å®Œæ•´ï¼Œè¯·åœ¨Webç•Œé¢ä¸­å®Œæˆé…ç½®")

        print("=" * 50)
    except Exception as e:
        print(f"âŒ è·å–é…ç½®ä¿¡æ¯å¤±è´¥: {e}")
        if not allow_incomplete:
            raise


if __name__ == "__main__":
    print_config_info(allow_incomplete=True)